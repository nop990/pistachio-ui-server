{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:18.595845Z",
     "start_time": "2025-03-25T04:00:18.593792Z"
    }
   },
   "source": [
    "# Pistachio is a player projection calculator for OOTP 2026 - it was originally developed for OOTP 2024\n",
    "# See explanatory video on the 'squirrel plays' YouTube channel\n",
    "# To configure export of data from game: OOTP 2026 and do Game > Game Settings > Database > Database Tools > Configure Data Export to CSV Files\n",
    "# Then to export data: Game > Game Settings > Database > Database Tools > Export Data to CSV Files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import toml\n",
    "import os\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 237
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:18.606595Z",
     "start_time": "2025-03-25T04:00:18.603524Z"
    }
   },
   "source": [
    "\n",
    "# this cell includes various things to configure the code to your saved game\n",
    "\n",
    "# specify the folder where the game saves csv files\n",
    "# Go to Game > Game Settings > Database > Database Tools > Open data import/export folder to find this\n",
    "# Go to Game > Game Settings > Database > Database Tools > Open data import\\export folder to find this\n",
    "config = toml.load('config/settings.toml')\n",
    "\n",
    "filepath = config['Settings']['csv_path']\n",
    "\n",
    "# specify the folder in which to save the outputs - this where the player lists will go once the code has done its calculations\n",
    "export_filepath = r'.\\reports'\n",
    "\n",
    "# specify the folder in which this .ipynb file, flagged.txt and club_lookup.csv are saved\n",
    "pistachio_filepath = os.getcwd()\n",
    "\n",
    "# identify the ID for your sporting director\n",
    "# look in the coaches.csv file for this - it is in the 'coach_id' column (look up the name of the sportng director in the 'last_name' column)\n",
    "ID = config['Settings']['scout_id']\n",
    "\n",
    "# identify the team being managed\n",
    "# this ensures all players for this team are included in the outputs - for other teams there are WAR-based cut-offs to prevent the outputs being too large\n",
    "# look in the 'club_lookup.csv' to see a list of team codes\n",
    "team_managed = config['Settings']['team_id']\n",
    "\n",
    "# set the minimum groundball percentage for a pitcher to be included in the outputs\n",
    "# setting this to 59 will include groundball and extreme groundball pitchers only; set this lower to include other types of pitchers (54 is league average)\n",
    "min_gb = config['Settings']['gb_weight']"
   ],
   "outputs": [],
   "execution_count": 238
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:19.145084Z",
     "start_time": "2025-03-25T04:00:18.619969Z"
    }
   },
   "source": [
    "# read in players from CSVs and remove retired players from dataframe\n",
    "df1 = pd.read_csv(filepath + '/players.csv')\n",
    "df1 = df1[df1.retired != 1]"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2324082954.py:2: DtypeWarning: Columns (35,69) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(filepath + '/players.csv')\n"
     ]
    }
   ],
   "execution_count": 239
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:19.286130Z",
     "start_time": "2025-03-25T04:00:19.159953Z"
    }
   },
   "source": [
    "# bring in scouted ratings - scouting coach id needs to be updated to the correct id for my team's scouting director\n",
    "df2 = pd.read_csv(filepath + '/players_scouted_ratings.csv')\n",
    "df2 = df2[df2.scouting_coach_id == ID]"
   ],
   "outputs": [],
   "execution_count": 240
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:19.316893Z",
     "start_time": "2025-03-25T04:00:19.300994Z"
    }
   },
   "source": [
    "# merge the dataframes\n",
    "merged_df = pd.merge(df1, df2, on='player_id')\n",
    "merged_df.rename(columns={'team_id_x': 'team_id'}, inplace=True)\n",
    "merged_df.rename(columns={'league_id_x': 'league_id'}, inplace=True)\n",
    "merged_df.rename(columns={'position_x': 'position'}, inplace=True)\n",
    "merged_df.rename(columns={'role_x': 'role'}, inplace=True)\n"
   ],
   "outputs": [],
   "execution_count": 241
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:20.025092Z",
     "start_time": "2025-03-25T04:00:19.327662Z"
    }
   },
   "source": [
    "# Read the player career stats csv file for hitters\n",
    "stats_df = pd.read_csv(filepath + '/players_career_batting_stats.csv')\n"
   ],
   "outputs": [],
   "execution_count": 242
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:20.073393Z",
     "start_time": "2025-03-25T04:00:20.041088Z"
    }
   },
   "source": [
    "# Filtering the dataframe for level_id = 1 and split_id = 1 (this means MLB stats and all pa not just for left or right handers)\n",
    "career_stats_df = stats_df[(stats_df['level_id'] == 1) & (stats_df['split_id'] == 1)]\n",
    "\n",
    "# summing the MLB career stats for each player id\n",
    "career_stats_df = career_stats_df.groupby('player_id')[['pa', 'bb', 'k', 'h', 'd', 't', 'hr', 'hp', 'pitches_seen']].sum().reset_index()\n",
    "\n",
    "# calculate MLB rate stats (hp = hit by pitch)\n",
    "career_stats_df['bb%_mlb'] = career_stats_df['bb'] / career_stats_df['pa']\n",
    "career_stats_df['k%_mlb'] = career_stats_df['k'] / career_stats_df['pa']\n",
    "career_stats_df['1b%_mlb'] = career_stats_df['h'] / career_stats_df['pa']\n",
    "career_stats_df['2b%_mlb'] = career_stats_df['d'] / career_stats_df['pa']\n",
    "career_stats_df['3b%_mlb'] = career_stats_df['t'] / career_stats_df['pa']\n",
    "career_stats_df['hr%_mlb'] = career_stats_df['hr'] / career_stats_df['pa']\n",
    "career_stats_df['hp%_mlb'] = career_stats_df['hp'] / career_stats_df['pa']\n",
    "career_stats_df['pitches/plate_appearance_mlb'] = career_stats_df['pitches_seen'] / career_stats_df['pa']\n",
    "\n",
    "# rename pa to pa_mlb (to prevent confusion with current single-season pa, which is just called pa further down)\n",
    "career_stats_df.rename(columns={'pa': 'pa_mlb'}, inplace=True)\n",
    "career_stats_df = career_stats_df.round(3)"
   ],
   "outputs": [],
   "execution_count": 243
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:20.108228Z",
     "start_time": "2025-03-25T04:00:20.086168Z"
    }
   },
   "source": [
    "# Merging career_stats_df into merged_df based on player_id\n",
    "columns_to_add = ['player_id', 'pa_mlb', 'bb%_mlb', 'k%_mlb', '1b%_mlb', '2b%_mlb', '3b%_mlb', 'hr%_mlb', 'hp%_mlb', 'pitches/plate_appearance_mlb']\n",
    "merged_df = merged_df.merge(career_stats_df[columns_to_add], on='player_id', how='left')\n"
   ],
   "outputs": [],
   "execution_count": 244
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:20.142574Z",
     "start_time": "2025-03-25T04:00:20.121038Z"
    }
   },
   "source": [
    "# Filter to get the latest year only and where split_id and level_id are both 1 (this means MLB stats and all pa not just for left or right handers)\n",
    "stats_df = stats_df[(stats_df['level_id'] == 1) & (stats_df['split_id'] == 1)]\n",
    "max_year = stats_df['year'].max()\n",
    "stats_df = stats_df[stats_df['year'] == max_year]\n",
    "stats_df = stats_df.groupby('player_id')[['ab', 'h', 'k', 'pa', 'pitches_seen', 'g', 'gs', 'd', 't', 'hr', 'r', 'rbi', 'sb', 'cs', 'bb', 'ibb', 'gdp', 'sh', 'sf', 'hp', 'ci', 'wpa', 'stint', 'ubr', 'war']].sum().reset_index()\n"
   ],
   "outputs": [],
   "execution_count": 245
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:20.172302Z",
     "start_time": "2025-03-25T04:00:20.156402Z"
    }
   },
   "source": [
    "# add single-season 'pa' and 'war' to merged_df and standardize war to 650 pa\n",
    "merged_df = pd.merge(merged_df, stats_df[['player_id', 'pa', 'war']], on='player_id', how='left')\n",
    "merged_df = merged_df.rename(columns={'war': 'WAR_actual'})\n",
    "merged_df['sWAR_actual'] = (650 / merged_df['pa']) * merged_df['WAR_actual']"
   ],
   "outputs": [],
   "execution_count": 246
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:20.846066Z",
     "start_time": "2025-03-25T04:00:20.186100Z"
    }
   },
   "source": [
    "# same idea but pulling out innings pitched for pitchers\n",
    "stats_df = pd.read_csv(filepath + '/players_career_pitching_stats.csv')\n",
    "stats_df = stats_df[(stats_df['level_id'] == 1) & (stats_df['split_id'] == 1)]\n",
    "max_year = stats_df['year'].max()\n",
    "stats_df = stats_df[stats_df['year'] == max_year]\n",
    "stats_df = stats_df.groupby('player_id')[['ip', 'war', 'ra9war']].sum().reset_index()\n",
    "merged_df = pd.merge(merged_df, stats_df[['player_id', 'ip', 'war', 'ra9war']], on='player_id', how='left')\n",
    "merged_df = merged_df.rename(columns={'war': 'WAR_actual_p'})\n",
    "merged_df['sWAR_actual_p'] = (180 / merged_df['ip']) * merged_df['WAR_actual_p']\n",
    "\n",
    "# replace NaN with blank in ip column\n",
    "merged_df['ip'].fillna('', inplace=True)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3050604111.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df['ip'].fillna('', inplace=True)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3050604111.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  merged_df['ip'].fillna('', inplace=True)\n"
     ]
    }
   ],
   "execution_count": 247
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:20.879423Z",
     "start_time": "2025-03-25T04:00:20.869643Z"
    }
   },
   "source": [
    "# drop columns from dataframe that are not needed\n",
    "\n",
    "# List of columns to drop\n",
    "columns_to_drop = [\n",
    "    \"nick_name\", \"city_of_birth_id\", \"nation_id\", \"second_nation_id\", \"last_league_id\",\n",
    "    \"last_team_id\", \"last_organization_id\", \"language_ids0\", \"language_ids1\", \"uniform_number\",\n",
    "    \"experience\", \"person_type\", \"historical_id\", \"historical_team_id\", \"best_contract_offer_id\",\n",
    "    \"injury_is_injured\", \"injury_dtd_injury\", \"injury_career_ending\", \"injury_dl_left\",\n",
    "    \"injury_dl_playoff_round\", \"injury_left\", \"dtd_injury_effect\", \"dtd_injury_effect_hit\",\n",
    "    \"dtd_injury_effect_throw\", \"dtd_injury_effect_run\", \"injury_id\", \"injury_id2\",\n",
    "    \"injury_dtd_injury2\", \"injury_left2\", \"dtd_injury_effect2\", \"dtd_injury_effect_hit2\",\n",
    "    \"dtd_injury_effect_throw2\", \"dtd_injury_effect_run2\", \"prone_overall\", \"prone_leg\",\n",
    "    \"prone_back\", \"prone_arm\", \"fatigue_pitches0\", \"fatigue_pitches1\", \"fatigue_pitches2\",\n",
    "    \"fatigue_pitches3\", \"fatigue_pitches4\", \"fatigue_pitches5\", \"fatigue_points\",\n",
    "    \"fatigue_played_today\", \"running_ratings_speed_x\", \"running_ratings_stealing_x\",\n",
    "    \"running_ratings_baserunning_x\", \"college\", \"school\",\n",
    "    \"commit_school\", \"hidden\", \"turned_coach\", \"hall_of_fame\", \"rust\", \"inducted\",\n",
    "    \"strategy_override_team\", \"strategy_stealing\", \"strategy_running\", \"strategy_bunt_for_hit\",\n",
    "    \"strategy_sac_bunt\", \"strategy_hit_run\", \"strategy_hook_start\", \"strategy_hook_relief\",\n",
    "    \"strategy_pitch_count\", \"strategy_pitch_around\", \"strategy_never_pinch_hit\",\n",
    "    \"strategy_defensive_sub\", \"strategy_dtd_sit_min\", \"strategy_dtd_allow_ph\", \"local_pop\",\n",
    "    \"national_pop\", \"draft_protected\", \"morale\", \"morale_player_performance\",\n",
    "    \"morale_team_performance\", \"morale_team_transactions\", \"expectation\", \"morale_player_role\",\n",
    "    \"on_loan\", \"loan_league_id\", \"loan_team_id\", \"team_id_y\", \"league_id_y\", \"position_y\", \"role_y\",\n",
    "    \"acquired\", \"acquired_date\", \"draft_year\", \"draft_round\", \"draft_supplemental\", \"draft_pick\",\n",
    "    \"draft_overall_pick\", \"draft_eligible\", \"hsc_status\", \"redshirt\", \"picked_in_draft\",\n",
    "    \"draft_league_id\", \"draft_team_id\", \"morale_mod\", \"morale_team_chemistry\",\n",
    "    \"scouting_coach_id\", \"scouting_team_id\"\n",
    "]\n",
    "\n",
    "# Drop the columns\n",
    "merged_df = merged_df.drop(columns=columns_to_drop, errors='ignore')\n"
   ],
   "outputs": [],
   "execution_count": 248
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:20.891732Z",
     "start_time": "2025-03-25T04:00:20.881465Z"
    }
   },
   "source": [
    "# create new columns to preseve the 20-80 scale ratings exported by OOTP 26 (actually this is on a 20-100 scale as super-ratings of 85, 90, 95 and 100 are possible)\n",
    "# Mapping of original column names to new names\n",
    "column_mapping = {\n",
    "    \"batting_ratings_overall_eye\": \"eye2080\",\n",
    "    \"batting_ratings_overall_strikeouts\": \"avK2080\",\n",
    "    \"batting_ratings_overall_power\": \"pow2080\",\n",
    "    \"batting_ratings_overall_gap\": \"gap2080\",\n",
    "    \"batting_ratings_overall_babip\": \"babip2080\",\n",
    "    \"batting_ratings_talent_eye\": \"eye2080p\",\n",
    "    \"batting_ratings_talent_strikeouts\": \"avK2080p\",\n",
    "    \"batting_ratings_talent_power\": \"pow2080p\",\n",
    "    \"batting_ratings_talent_gap\": \"gap2080p\",\n",
    "    \"batting_ratings_talent_babip\": \"babip2080p\",\n",
    "    \"fielding_ratings_catcher_ability\": \"cabi2080\",\n",
    "    \"fielding_ratings_catcher_arm\": \"carm2080\",\n",
    "    \"fielding_ratings_infield_range\": \"ifrng2080\",\n",
    "    \"fielding_ratings_infield_error\": \"iferr2080\",\n",
    "    \"fielding_ratings_infield_arm\": \"ifarm2080\",\n",
    "    \"fielding_ratings_turn_doubleplay\": \"turndp2080\",\n",
    "    \"fielding_ratings_outfield_arm\": \"ofarm2080\",\n",
    "    \"fielding_ratings_outfield_range\": \"ofrng2080\",\n",
    "    \"fielding_ratings_outfield_error\": \"oferr2080\",\n",
    "    \"pitching_ratings_pitches_fastball\": \"fb2080\",\n",
    "    \"pitching_ratings_pitches_slider\": \"sl2080\",\n",
    "    \"pitching_ratings_pitches_curveball\": \"crv2080\",\n",
    "    \"pitching_ratings_pitches_screwball\": \"scrw2080\",\n",
    "    \"pitching_ratings_pitches_forkball\": \"frk2080\",\n",
    "    \"pitching_ratings_pitches_changeup\": \"chng2080\",\n",
    "    \"pitching_ratings_pitches_sinker\": \"sink2080\",\n",
    "    \"pitching_ratings_pitches_splitter\": \"spli2080\",\n",
    "    \"pitching_ratings_pitches_knuckleball\": \"knuc2080\",\n",
    "    \"pitching_ratings_pitches_cutter\": \"cut2080\",\n",
    "    \"pitching_ratings_pitches_circlechange\": \"cchng2080\",\n",
    "    \"pitching_ratings_pitches_knucklecurve\": \"kcurv2080\",\n",
    "    \"pitching_ratings_misc_stamina\": \"stam2080\",\n",
    "    \"pitching_ratings_overall_stuff\": \"stuff2080\",\n",
    "    \"pitching_ratings_overall_control\": \"ctrl2080\",\n",
    "    \"pitching_ratings_overall_movement\": \"mvt2080\",\n",
    "    \"pitching_ratings_overall_hra\": \"hra2080\",\n",
    "    \"pitching_ratings_overall_pbabip\": \"pbabip2080\",\n",
    "    \"pitching_ratings_pitches_talent_fastball\": \"fb2080p\",\n",
    "    \"pitching_ratings_pitches_talent_slider\": \"sl2080p\",\n",
    "    \"pitching_ratings_pitches_talent_curveball\": \"crv2080p\",\n",
    "    \"pitching_ratings_pitches_talent_screwball\": \"scrw2080p\",\n",
    "    \"pitching_ratings_pitches_talent_forkball\": \"frk2080p\",\n",
    "    \"pitching_ratings_pitches_talent_changeup\": \"chng2080p\",\n",
    "    \"pitching_ratings_pitches_talent_sinker\": \"sink2080p\",\n",
    "    \"pitching_ratings_pitches_talent_splitter\": \"spli2080p\",\n",
    "    \"pitching_ratings_pitches_talent_knuckleball\": \"knuc2080p\",\n",
    "    \"pitching_ratings_pitches_talent_cutter\": \"cut2080p\",\n",
    "    \"pitching_ratings_pitches_talent_circlechange\": \"cchng2080p\",\n",
    "    \"pitching_ratings_pitches_talent_knucklecurve\": \"kcurv2080p\",\n",
    "    \"pitching_ratings_talent_stuff\": \"stuff2080p\",\n",
    "    \"pitching_ratings_talent_control\": \"ctrl2080p\",\n",
    "    \"pitching_ratings_talent_movement\": \"mvt2080p\",\n",
    "    \"pitching_ratings_talent_hra\": \"hra2080p\",\n",
    "    \"pitching_ratings_talent_pbabip\": \"pbabip2080p\" \n",
    "}\n",
    "\n",
    "# Create duplicate columns in merged_df with new names\n",
    "for original_col, new_col in column_mapping.items():\n",
    "    if original_col in merged_df.columns:\n",
    "        merged_df[new_col] = merged_df[original_col]"
   ],
   "outputs": [],
   "execution_count": 249
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:20.939924Z",
     "start_time": "2025-03-25T04:00:20.903008Z"
    }
   },
   "source": [
    "# replace the 20-100 ratings with ratings on a 1-250 scale in line with the export from OOTP 2024, which the calculations below are based on\n",
    "\n",
    "# Define the find-replace mapping between the 20-100 scale and the 1-250 scale\n",
    "replace_map = {\n",
    "    20: 6,  25: 20,  30: 35,  35: 52,  40: 69,\n",
    "    45: 85,  50: 101,  55: 117,  60: 134,  65: 150,\n",
    "    70: 166,  75: 181,  80: 201,  85: 213,  90: 225,\n",
    "    95: 238,  100: 250\n",
    "}\n",
    "\n",
    "# List of columns to apply the replacement\n",
    "columns_to_replace = [\n",
    "    \"batting_ratings_overall_eye\", \"batting_ratings_overall_strikeouts\",\n",
    "    \"batting_ratings_overall_power\", \"batting_ratings_overall_gap\",\n",
    "    \"batting_ratings_overall_babip\", \"batting_ratings_talent_eye\",\n",
    "    \"batting_ratings_talent_strikeouts\", \"batting_ratings_talent_power\",\n",
    "    \"batting_ratings_talent_gap\", \"batting_ratings_talent_babip\",\n",
    "    \"fielding_ratings_catcher_ability\", \"fielding_ratings_catcher_arm\", \"fielding_ratings_catcher_framing\",\n",
    "    \"fielding_ratings_infield_range\", \"fielding_ratings_infield_error\",\n",
    "    \"fielding_ratings_infield_arm\", \"fielding_ratings_turn_doubleplay\",\n",
    "    \"fielding_ratings_outfield_arm\", \"fielding_ratings_outfield_range\",\n",
    "    \"fielding_ratings_outfield_error\", \"pitching_ratings_pitches_fastball\",\n",
    "    \"pitching_ratings_pitches_slider\", \"pitching_ratings_pitches_curveball\",\n",
    "    \"pitching_ratings_pitches_screwball\", \"pitching_ratings_pitches_forkball\",\n",
    "    \"pitching_ratings_pitches_changeup\", \"pitching_ratings_pitches_sinker\",\n",
    "    \"pitching_ratings_pitches_splitter\", \"pitching_ratings_pitches_knuckleball\",\n",
    "    \"pitching_ratings_pitches_cutter\", \"pitching_ratings_pitches_circlechange\",\n",
    "    \"pitching_ratings_pitches_knucklecurve\", \"pitching_ratings_misc_stamina\",\n",
    "    \"pitching_ratings_overall_stuff\", \"pitching_ratings_overall_control\",\n",
    "    \"pitching_ratings_overall_movement\", \"pitching_ratings_pitches_talent_fastball\",\n",
    "    \"pitching_ratings_pitches_talent_slider\", \"pitching_ratings_pitches_talent_curveball\",\n",
    "    \"pitching_ratings_pitches_talent_screwball\", \"pitching_ratings_pitches_talent_forkball\",\n",
    "    \"pitching_ratings_pitches_talent_changeup\", \"pitching_ratings_pitches_talent_sinker\",\n",
    "    \"pitching_ratings_pitches_talent_splitter\", \"pitching_ratings_pitches_talent_knuckleball\",\n",
    "    \"pitching_ratings_pitches_talent_cutter\", \"pitching_ratings_pitches_talent_circlechange\",\n",
    "    \"pitching_ratings_pitches_talent_knucklecurve\", \"pitching_ratings_talent_stuff\",\n",
    "    \"pitching_ratings_talent_control\", \"pitching_ratings_talent_movement\"\n",
    "]\n",
    "\n",
    "# Apply the replacement\n",
    "merged_df[columns_to_replace] = merged_df[columns_to_replace].replace(replace_map)\n"
   ],
   "outputs": [],
   "execution_count": 250
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:21.043005Z",
     "start_time": "2025-03-25T04:00:20.952842Z"
    }
   },
   "source": [
    "# calculate standardized WAR for hitters based on the MOPS projection system by Sgt Mushroom\n",
    "\n",
    "# calculate bb%\n",
    "def calculate_bb(row):\n",
    "    if row['batting_ratings_overall_eye'] <= 100:\n",
    "        return ((row['batting_ratings_overall_eye'] * 0.0007268758188) + 0.001460739)\n",
    "    elif row['batting_ratings_overall_eye'] > 100:\n",
    "        return ((row['batting_ratings_overall_eye'] * 0.0012280964) - 0.0469974639)\n",
    "\n",
    "merged_df['bb%'] = merged_df.apply(calculate_bb, axis=1)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\664076993.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['bb%'] = merged_df.apply(calculate_bb, axis=1)\n"
     ]
    }
   ],
   "execution_count": 251
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:21.130048Z",
     "start_time": "2025-03-25T04:00:21.055302Z"
    }
   },
   "source": [
    "# calculate k% (with fudge factor to account for high avK players having too high a OPS+ projection vs career performance - this is based on OOTP 24 gameplay experience)\n",
    "# 0.1 is the fudge factor - this is applied here and in the potential calculations\n",
    "# strikeout rating also capped at 180 to prevent sky-high k% projections\n",
    "# before adding this players with high avK and gap power but low HR power were getting too high of an OPS+ projection\n",
    "\n",
    "def calculate_k(row):\n",
    "    # Cap batting_ratings_overall_strikeouts at 180\n",
    "    strikeouts = min(row['batting_ratings_overall_strikeouts'], 180)\n",
    "\n",
    "    # Adjusted strikeouts calculation\n",
    "    adjusted_strikeouts = strikeouts + ((100 - strikeouts) * 0.1)\n",
    "\n",
    "    # Apply formula based on strikeout level\n",
    "    if strikeouts <= 100:\n",
    "        return (adjusted_strikeouts * -0.002454367) + 0.4655792299\n",
    "    elif 101 <= strikeouts <= 220:\n",
    "        return (adjusted_strikeouts * -0.0016592514) + 0.383395059\n",
    "    else:\n",
    "        return (adjusted_strikeouts * 0) + 0.02385\n",
    "\n",
    "# Apply function to calculate 'k%'\n",
    "merged_df['k%'] = merged_df.apply(calculate_k, axis=1)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1250504945.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['k%'] = merged_df.apply(calculate_k, axis=1)\n"
     ]
    }
   ],
   "execution_count": 252
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:21.232743Z",
     "start_time": "2025-03-25T04:00:21.141831Z"
    }
   },
   "source": [
    "# add new function to calculate hr%\n",
    "def calculate_hr(row):\n",
    "    if row['batting_ratings_overall_power'] <= 100:\n",
    "        return (row['batting_ratings_overall_power'] * 0.0001965717055) + 0.0057097943\n",
    "    elif row['batting_ratings_overall_power'] > 100:\n",
    "        return (row['batting_ratings_overall_power'] * 0.0005767110238) - 0.0305087264\n",
    "\n",
    "merged_df['hr%'] = merged_df.apply(calculate_hr, axis=1)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3047627861.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['hr%'] = merged_df.apply(calculate_hr, axis=1)\n"
     ]
    }
   ],
   "execution_count": 253
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:21.513495Z",
     "start_time": "2025-03-25T04:00:21.245565Z"
    }
   },
   "source": [
    "# Adjusted function to calculate part1_2b with fudge factor to reduce impact of batting_ratings_overall_gap (0.6666 is the fudge factor)\n",
    "def calculate_part1_2b(row):\n",
    "    # Reduce impact by adjusting the distance to 100\n",
    "    adjusted_gap = row['batting_ratings_overall_gap'] - ((row['batting_ratings_overall_gap'] - 100) * 0.6666)\n",
    "    return (adjusted_gap * 0.0005759923464) + 0.0046460781\n",
    "\n",
    "# Function to calculate part2_2b\n",
    "def calculate_part2_2b(row):\n",
    "    if row['batting_ratings_overall_power'] <= 100:\n",
    "        return (row['batting_ratings_overall_power'] * -0.0000508547503) + 0.0669597896 - 0.0628\n",
    "    else:\n",
    "        return (row['batting_ratings_overall_power'] * -0.00008542726043) + 0.071154717 - 0.0628\n",
    "\n",
    "# Function to calculate part3_2b\n",
    "def calculate_part3_2b(row):\n",
    "    if row['batting_ratings_overall_strikeouts'] <= 100:\n",
    "        return (row['batting_ratings_overall_strikeouts'] * -0.0002084865135) + 0.0828934273 - 0.0628\n",
    "    elif 101 <= row['batting_ratings_overall_strikeouts'] <= 220:\n",
    "        return (row['batting_ratings_overall_strikeouts'] * -0.000008259599351) + 0.0708287518 - 0.0628\n",
    "    else:\n",
    "        return (row['batting_ratings_overall_strikeouts'] * 0) + 0.053 - 0.0628\n",
    "\n",
    "# Apply calculations to dataframe\n",
    "merged_df['part1_2b'] = merged_df.apply(calculate_part1_2b, axis=1)\n",
    "merged_df['part2_2b'] = merged_df.apply(calculate_part2_2b, axis=1)\n",
    "merged_df['part3_2b'] = merged_df.apply(calculate_part3_2b, axis=1)\n",
    "\n",
    "# Compute final 2b% value\n",
    "merged_df['2b%'] = merged_df['part1_2b'] + merged_df['part2_2b'] + merged_df['part3_2b']\n",
    "\n",
    "# Drop the intermediate calculations from the dataframe\n",
    "merged_df = merged_df.drop(columns=['part1_2b', 'part2_2b', 'part3_2b'])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\599612034.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part1_2b'] = merged_df.apply(calculate_part1_2b, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\599612034.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part2_2b'] = merged_df.apply(calculate_part2_2b, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\599612034.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part3_2b'] = merged_df.apply(calculate_part3_2b, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\599612034.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['2b%'] = merged_df['part1_2b'] + merged_df['part2_2b'] + merged_df['part3_2b']\n"
     ]
    }
   ],
   "execution_count": 254
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:21.813378Z",
     "start_time": "2025-03-25T04:00:21.526310Z"
    }
   },
   "source": [
    "# add new function to calculate 3b%\n",
    "\n",
    "def calculate_part1_3b(row):\n",
    "    return (row['batting_ratings_overall_gap'] * 0.00004451978242) + 0.00007767274633\n",
    "\n",
    "def calculate_part2_3b(row):\n",
    "    if row['batting_ratings_overall_power'] <= 100:\n",
    "        return (row['batting_ratings_overall_power'] * -0.00000206286281) + 0.0046134367 - 0.0044\n",
    "    else:\n",
    "        return (row['batting_ratings_overall_power'] * -0.000007041275071) + 0.0051236727 - 0.0044\n",
    "\n",
    "def calculate_part3_3b(row):\n",
    "    if row['batting_ratings_overall_strikeouts'] <= 100:\n",
    "        return (row['batting_ratings_overall_strikeouts'] * -0.00001098275967) + 0.0055735013 - 0.0044\n",
    "    elif 101 <= row['batting_ratings_overall_strikeouts'] <= 220:\n",
    "        return (row['batting_ratings_overall_strikeouts'] * -0.00000526736139) + 0.0048976614 - 0.0044\n",
    "    else:\n",
    "        return (row['batting_ratings_overall_strikeouts'] * 0) + 0.0037 - 0.0044\n",
    "\n",
    "merged_df['part1_3b'] = merged_df.apply(calculate_part1_3b, axis=1)\n",
    "merged_df['part2_3b'] = merged_df.apply(calculate_part2_3b, axis=1)\n",
    "merged_df['part3_3b'] = merged_df.apply(calculate_part3_3b, axis=1)\n",
    "\n",
    "merged_df['3b%'] = merged_df['part1_3b'] + merged_df['part2_3b'] + merged_df['part3_3b']\n",
    "\n",
    "# Drop the intermediate calculations from the dataframe\n",
    "merged_df = merged_df.drop(columns=['part1_3b', 'part2_3b', 'part3_3b'])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\4052012128.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part1_3b'] = merged_df.apply(calculate_part1_3b, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\4052012128.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part2_3b'] = merged_df.apply(calculate_part2_3b, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\4052012128.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part3_3b'] = merged_df.apply(calculate_part3_3b, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\4052012128.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['3b%'] = merged_df['part1_3b'] + merged_df['part2_3b'] + merged_df['part3_3b']\n"
     ]
    }
   ],
   "execution_count": 255
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:22.082188Z",
     "start_time": "2025-03-25T04:00:21.826180Z"
    }
   },
   "source": [
    "# calculate 1b%\n",
    "\n",
    "def calculate_part1_1b(row):\n",
    "    if row['batting_ratings_overall_babip'] <= 100:\n",
    "        return (row['batting_ratings_overall_babip'] * 0.0015140038) + 0.1281801944\n",
    "    else:\n",
    "        return (row['batting_ratings_overall_babip'] * 0.000964994955) + 0.1837822012\n",
    "\n",
    "def calculate_part2_1b(row):\n",
    "    return (row['batting_ratings_overall_gap'] * -0.0003887320573) + 0.3178756912 - 0.28\n",
    "\n",
    "def calculate_part3_1b(row):\n",
    "    if row['batting_ratings_overall_strikeouts'] <= 100:\n",
    "        return (row['batting_ratings_overall_strikeouts'] * 0.000149985378) + 0.2648525907 - 0.28\n",
    "    elif 101 <= row['batting_ratings_overall_strikeouts'] <= 220:\n",
    "        return (row['batting_ratings_overall_strikeouts'] * 0.00005179135613) + 0.2754044069 - 0.28\n",
    "    else:\n",
    "        return (row['batting_ratings_overall_strikeouts'] * 0) + 0.286 - 0.28\n",
    "\n",
    "merged_df['part1_1b'] = merged_df.apply(calculate_part1_1b, axis=1)\n",
    "merged_df['part2_1b'] = merged_df.apply(calculate_part2_1b, axis=1)\n",
    "merged_df['part3_1b'] = merged_df.apply(calculate_part3_1b, axis=1)\n",
    "\n",
    "merged_df['1b%'] = merged_df['part1_1b'] + merged_df['part2_1b'] + merged_df['part3_1b']\n",
    "\n",
    "# Drop the intermediate calculations from the dataframe\n",
    "merged_df = merged_df.drop(columns=['part1_1b', 'part2_1b', 'part3_1b'])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3200180966.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part1_1b'] = merged_df.apply(calculate_part1_1b, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3200180966.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part2_1b'] = merged_df.apply(calculate_part2_1b, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3200180966.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part3_1b'] = merged_df.apply(calculate_part3_1b, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3200180966.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['1b%'] = merged_df['part1_1b'] + merged_df['part2_1b'] + merged_df['part3_1b']\n"
     ]
    }
   ],
   "execution_count": 256
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:22.099114Z",
     "start_time": "2025-03-25T04:00:22.094964Z"
    }
   },
   "source": [
    "# calculate Offensive Runs Created per game (orc_per_game)\n",
    "merged_df['orc_per_game'] = ((merged_df['bb%'] - 0.0738) / 0.875) + ((merged_df['k%'] - 0.2195) / -1.217) + ((merged_df['hr%'] - 0.0272) / 0.219) + ((merged_df['2b%'] - 0.0628) / 0.693) + ((merged_df['3b%'] - 0.0044) / 0.0519) + ((merged_df['1b%'] - 0.28) / 0.594)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3937084388.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['orc_per_game'] = ((merged_df['bb%'] - 0.0738) / 0.875) + ((merged_df['k%'] - 0.2195) / -1.217) + ((merged_df['hr%'] - 0.0272) / 0.219) + ((merged_df['2b%'] - 0.0628) / 0.693) + ((merged_df['3b%'] - 0.0044) / 0.0519) + ((merged_df['1b%'] - 0.28) / 0.594)\n"
     ]
    }
   ],
   "execution_count": 257
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:22.114556Z",
     "start_time": "2025-03-25T04:00:22.110862Z"
    }
   },
   "source": [
    "# calculate offensive WAR\n",
    "merged_df['toWAR'] = (merged_df['orc_per_game'] * 162) / 10"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2583026884.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['toWAR'] = (merged_df['orc_per_game'] * 162) / 10\n"
     ]
    }
   ],
   "execution_count": 258
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:22.313964Z",
     "start_time": "2025-03-25T04:00:22.139684Z"
    }
   },
   "source": [
    "# calculate c_def (catcher defense)\n",
    "\n",
    "def calculate_part1_c_def(row):\n",
    "    if row['fielding_ratings_catcher_framing'] <= 40:\n",
    "        return (row['fielding_ratings_catcher_framing'] * 0) + 5.311\n",
    "    elif 41 <= row['fielding_ratings_catcher_framing'] <= 61:\n",
    "        return (row['fielding_ratings_catcher_framing'] * -0.0204) + 6.125\n",
    "    else:\n",
    "        return (row['fielding_ratings_catcher_framing'] * -0.0028608333) + 4.998622222\n",
    "\n",
    "def calculate_part2_c_def(row):\n",
    "    return (row['fielding_ratings_catcher_arm'] * -0.0006034965035) + 4.712621212\n",
    "\n",
    "merged_df['part1_c_def'] = merged_df.apply(calculate_part1_c_def, axis=1)\n",
    "merged_df['part2_c_def'] = merged_df.apply(calculate_part2_c_def, axis=1)\n",
    "\n",
    "merged_df['c_def'] = 4.6385 - merged_df['part1_c_def'] + 4.6385 - merged_df['part2_c_def']\n",
    "\n",
    "# Drop the intermediate calculations from the dataframe\n",
    "merged_df = merged_df.drop(columns=['part1_c_def', 'part2_c_def'])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\385872285.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part1_c_def'] = merged_df.apply(calculate_part1_c_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\385872285.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part2_c_def'] = merged_df.apply(calculate_part2_c_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\385872285.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['c_def'] = 4.6385 - merged_df['part1_c_def'] + 4.6385 - merged_df['part2_c_def']\n"
     ]
    }
   ],
   "execution_count": 259
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:22.723674Z",
     "start_time": "2025-03-25T04:00:22.327798Z"
    }
   },
   "source": [
    "# calculate 1b_def\n",
    "\n",
    "def calculate_part1_1b_def(row):\n",
    "    return (row['height'] * -0.0014708625) + 4.917895105\n",
    "\n",
    "def calculate_part2_1b_def(row):\n",
    "    return (row['fielding_ratings_infield_range'] * -0.0001325174825) + 4.645893939\n",
    "\n",
    "def calculate_part3_1b_def(row):\n",
    "    return (row['fielding_ratings_infield_error'] * -0.0001685314685) + 4.658242424\n",
    "\n",
    "def calculate_part4_1b_def(row):\n",
    "    return (row['fielding_ratings_infield_arm'] * 0) + 4.6385\n",
    "\n",
    "def calculate_part5_1b_def(row):\n",
    "    return (row['fielding_ratings_turn_doubleplay'] * 0) + 4.6385\n",
    "\n",
    "merged_df['part1_1b_def'] = merged_df.apply(calculate_part1_1b_def, axis=1)\n",
    "merged_df['part2_1b_def'] = merged_df.apply(calculate_part2_1b_def, axis=1)\n",
    "merged_df['part3_1b_def'] = merged_df.apply(calculate_part3_1b_def, axis=1)\n",
    "merged_df['part4_1b_def'] = merged_df.apply(calculate_part4_1b_def, axis=1)\n",
    "merged_df['part5_1b_def'] = merged_df.apply(calculate_part5_1b_def, axis=1)\n",
    "\n",
    "merged_df['1b_def'] = 4.6385 - merged_df['part1_1b_def'] + 4.6385 - merged_df['part2_1b_def'] + 4.6385 - merged_df['part3_1b_def'] + 4.6385 - merged_df['part4_1b_def'] + 4.6385 - merged_df['part5_1b_def']\n",
    "\n",
    "# Drop the intermediate calculations from the dataframe\n",
    "merged_df = merged_df.drop(columns=['part1_1b_def', 'part2_1b_def', 'part3_1b_def', 'part4_1b_def', 'part5_1b_def'])\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\4182666379.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part1_1b_def'] = merged_df.apply(calculate_part1_1b_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\4182666379.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part2_1b_def'] = merged_df.apply(calculate_part2_1b_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\4182666379.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part3_1b_def'] = merged_df.apply(calculate_part3_1b_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\4182666379.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part4_1b_def'] = merged_df.apply(calculate_part4_1b_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\4182666379.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part5_1b_def'] = merged_df.apply(calculate_part5_1b_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\4182666379.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['1b_def'] = 4.6385 - merged_df['part1_1b_def'] + 4.6385 - merged_df['part2_1b_def'] + 4.6385 - merged_df['part3_1b_def'] + 4.6385 - merged_df['part4_1b_def'] + 4.6385 - merged_df['part5_1b_def']\n"
     ]
    }
   ],
   "execution_count": 260
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:23.079151Z",
     "start_time": "2025-03-25T04:00:22.738052Z"
    }
   },
   "source": [
    "# calculate 2b_def\n",
    "\n",
    "def calculate_part1_2b_def(row):\n",
    "    if row['fielding_ratings_turn_doubleplay'] <= 200:\n",
    "        return (row['fielding_ratings_turn_doubleplay'] * -0.0012715152) + 4.825866667\n",
    "    else:\n",
    "        return (row['fielding_ratings_turn_doubleplay'] * 0) + 4.569020596\n",
    "\n",
    "def calculate_part2_2b_def(row):\n",
    "    return (row['fielding_ratings_infield_range'] * -0.0016293706) + 4.844484848\n",
    "\n",
    "def calculate_part3_2b_def(row):\n",
    "    if row['fielding_ratings_infield_error'] <= 160:\n",
    "        return (row['fielding_ratings_infield_error'] * -0.0006464285714) + 4.720428571\n",
    "    else:\n",
    "        return (row['fielding_ratings_infield_error'] * 0) + 4.628635714\n",
    "\n",
    "def calculate_part4_2b_def(row):\n",
    "    return (row['fielding_ratings_infield_arm'] * -0.0002284965035) + 4.658287879\n",
    "\n",
    "merged_df['part1_2b_def'] = merged_df.apply(calculate_part1_2b_def, axis=1)\n",
    "merged_df['part2_2b_def'] = merged_df.apply(calculate_part2_2b_def, axis=1)\n",
    "merged_df['part3_2b_def'] = merged_df.apply(calculate_part3_2b_def, axis=1)\n",
    "merged_df['part4_2b_def'] = merged_df.apply(calculate_part4_2b_def, axis=1)\n",
    "\n",
    "merged_df['2b_def'] = 4.6385 - merged_df['part1_2b_def'] + 4.6385 - merged_df['part2_2b_def'] + 4.6385 - merged_df['part3_2b_def'] + 4.6385 - merged_df['part4_2b_def']\n",
    "\n",
    "# Drop the intermediate calculations from the dataframe\n",
    "merged_df = merged_df.drop(columns=['part1_2b_def', 'part2_2b_def', 'part3_2b_def', 'part4_2b_def'])\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2222392647.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part1_2b_def'] = merged_df.apply(calculate_part1_2b_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2222392647.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part2_2b_def'] = merged_df.apply(calculate_part2_2b_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2222392647.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part3_2b_def'] = merged_df.apply(calculate_part3_2b_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2222392647.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part4_2b_def'] = merged_df.apply(calculate_part4_2b_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2222392647.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['2b_def'] = 4.6385 - merged_df['part1_2b_def'] + 4.6385 - merged_df['part2_2b_def'] + 4.6385 - merged_df['part3_2b_def'] + 4.6385 - merged_df['part4_2b_def']\n"
     ]
    }
   ],
   "execution_count": 261
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:23.451370Z",
     "start_time": "2025-03-25T04:00:23.092436Z"
    }
   },
   "source": [
    "# calculate 3b_def\n",
    "\n",
    "def calculate_part1_3b_def(row):\n",
    "    return (row['fielding_ratings_turn_doubleplay'] * 0) + 4.6385\n",
    "\n",
    "def calculate_part2_3b_def(row):\n",
    "    return (row['fielding_ratings_infield_range'] * -0.0015907343) + 4.808545455\n",
    "\n",
    "def calculate_part3_3b_def(row):\n",
    "    if row['fielding_ratings_infield_error'] <= 180:\n",
    "        return (row['fielding_ratings_infield_error'] * -0.0008091666667) + 4.748583333\n",
    "    else:\n",
    "        return (row['fielding_ratings_infield_error'] * 0) + 4.61\n",
    "\n",
    "def calculate_part4_3b_def(row):\n",
    "    if row['fielding_ratings_infield_arm'] <= 60:\n",
    "        return (row['fielding_ratings_infield_arm'] * 0) + 4.788\n",
    "    else:\n",
    "        return (row['fielding_ratings_infield_arm'] * -0.0021283333) + 4.963644444\n",
    "\n",
    "merged_df['part1_3b_def'] = merged_df.apply(calculate_part1_3b_def, axis=1)\n",
    "merged_df['part2_3b_def'] = merged_df.apply(calculate_part2_3b_def, axis=1)\n",
    "merged_df['part3_3b_def'] = merged_df.apply(calculate_part3_3b_def, axis=1)\n",
    "merged_df['part4_3b_def'] = merged_df.apply(calculate_part4_3b_def, axis=1)\n",
    "\n",
    "merged_df['3b_def'] = 4.6385 - merged_df['part1_3b_def'] + 4.6385 - merged_df['part2_3b_def'] + 4.6385 - merged_df['part3_3b_def'] + 4.6385 - merged_df['part4_3b_def']\n",
    "\n",
    "# Drop the intermediate calculations from the dataframe\n",
    "merged_df = merged_df.drop(columns=['part1_3b_def', 'part2_3b_def', 'part3_3b_def', 'part4_3b_def'])\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2545872336.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part1_3b_def'] = merged_df.apply(calculate_part1_3b_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2545872336.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part2_3b_def'] = merged_df.apply(calculate_part2_3b_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2545872336.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part3_3b_def'] = merged_df.apply(calculate_part3_3b_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2545872336.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part4_3b_def'] = merged_df.apply(calculate_part4_3b_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2545872336.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['3b_def'] = 4.6385 - merged_df['part1_3b_def'] + 4.6385 - merged_df['part2_3b_def'] + 4.6385 - merged_df['part3_3b_def'] + 4.6385 - merged_df['part4_3b_def']\n"
     ]
    }
   ],
   "execution_count": 262
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:23.824066Z",
     "start_time": "2025-03-25T04:00:23.463686Z"
    }
   },
   "source": [
    "# calculate ss_def\n",
    "\n",
    "def calculate_part1_ss_def(row):\n",
    "    if row['fielding_ratings_turn_doubleplay'] <= 200:\n",
    "        return (row['fielding_ratings_turn_doubleplay'] * -0.0007603030303) + 4.7435333333\n",
    "    else:\n",
    "        return (row['fielding_ratings_turn_doubleplay'] * 0) + 4.597\n",
    "\n",
    "def calculate_part2_ss_def(row):\n",
    "    if row['fielding_ratings_infield_range'] <= 60:\n",
    "        return (row['fielding_ratings_infield_range'] * 0) + 4.985\n",
    "    else:\n",
    "        return (row['fielding_ratings_infield_range'] * -0.0045308333) + 5.330155556\n",
    "\n",
    "def calculate_part3_ss_def(row):\n",
    "    if row['fielding_ratings_infield_error'] <= 180:\n",
    "        return (row['fielding_ratings_infield_error'] * -0.0011291667) + 4.793027778\n",
    "    else:\n",
    "        return (row['fielding_ratings_infield_error'] * 0) + 4.588\n",
    "\n",
    "def calculate_part4_ss_def(row):\n",
    "    return (row['fielding_ratings_infield_arm'] * -0.0011823427) + 4.809787879\n",
    "\n",
    "merged_df['part1_ss_def'] = merged_df.apply(calculate_part1_ss_def, axis=1)\n",
    "merged_df['part2_ss_def'] = merged_df.apply(calculate_part2_ss_def, axis=1)\n",
    "merged_df['part3_ss_def'] = merged_df.apply(calculate_part3_ss_def, axis=1)\n",
    "merged_df['part4_ss_def'] = merged_df.apply(calculate_part4_ss_def, axis=1)\n",
    "\n",
    "merged_df['ss_def'] = 4.6385 - merged_df['part1_ss_def'] + 4.6385 - merged_df['part2_ss_def'] + 4.6385 - merged_df['part3_ss_def'] + 4.6385 - merged_df['part4_ss_def']\n",
    "\n",
    "# Drop the intermediate calculations from the dataframe\n",
    "merged_df = merged_df.drop(columns=['part1_ss_def', 'part2_ss_def', 'part3_ss_def', 'part4_ss_def'])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2722684677.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part1_ss_def'] = merged_df.apply(calculate_part1_ss_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2722684677.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part2_ss_def'] = merged_df.apply(calculate_part2_ss_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2722684677.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part3_ss_def'] = merged_df.apply(calculate_part3_ss_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2722684677.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part4_ss_def'] = merged_df.apply(calculate_part4_ss_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2722684677.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['ss_def'] = 4.6385 - merged_df['part1_ss_def'] + 4.6385 - merged_df['part2_ss_def'] + 4.6385 - merged_df['part3_ss_def'] + 4.6385 - merged_df['part4_ss_def']\n"
     ]
    }
   ],
   "execution_count": 263
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:24.107979Z",
     "start_time": "2025-03-25T04:00:23.837935Z"
    }
   },
   "source": [
    "# calculate lf_def\n",
    "\n",
    "def calculate_part1_lf_def(row):\n",
    "    return (row['fielding_ratings_outfield_arm'] * -0.000190034965) + 4.665287879\n",
    "\n",
    "def calculate_part2_lf_def(row):\n",
    "    if row['fielding_ratings_outfield_range'] <= 40:\n",
    "        return (row['fielding_ratings_outfield_range'] * 0) + 4.9135\n",
    "    elif 41 <= row['fielding_ratings_outfield_range'] <= 80:\n",
    "        return (row['fielding_ratings_outfield_range'] * -0.000825) + 4.9445\n",
    "    elif 81 <= row['fielding_ratings_outfield_range'] <= 100:\n",
    "        return (row['fielding_ratings_outfield_range'] * -0.01135) + 5.787\n",
    "    elif 101 <= row['fielding_ratings_outfield_range'] <= 180:\n",
    "        return (row['fielding_ratings_outfield_range'] * -0.000625) + 4.661\n",
    "    else:\n",
    "        return (row['fielding_ratings_outfield_range'] * 0) + 4.54\n",
    "\n",
    "def calculate_part3_lf_def(row):\n",
    "    return (row['fielding_ratings_outfield_error'] * 0) + 4.6385\n",
    "\n",
    "merged_df['part1_lf_def'] = merged_df.apply(calculate_part1_lf_def, axis=1)\n",
    "merged_df['part2_lf_def'] = merged_df.apply(calculate_part2_lf_def, axis=1)\n",
    "merged_df['part3_lf_def'] = merged_df.apply(calculate_part3_lf_def, axis=1)\n",
    "\n",
    "merged_df['lf_def'] = 4.6385 - merged_df['part1_lf_def'] + 4.6385 - merged_df['part2_lf_def'] + 4.6385 - merged_df['part3_lf_def']\n",
    "\n",
    "# Drop the intermediate calculations from the dataframe\n",
    "merged_df = merged_df.drop(columns=['part1_lf_def', 'part2_lf_def', 'part3_lf_def'])\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\330519813.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part1_lf_def'] = merged_df.apply(calculate_part1_lf_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\330519813.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part2_lf_def'] = merged_df.apply(calculate_part2_lf_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\330519813.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part3_lf_def'] = merged_df.apply(calculate_part3_lf_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\330519813.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['lf_def'] = 4.6385 - merged_df['part1_lf_def'] + 4.6385 - merged_df['part2_lf_def'] + 4.6385 - merged_df['part3_lf_def']\n"
     ]
    }
   ],
   "execution_count": 264
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:24.374580Z",
     "start_time": "2025-03-25T04:00:24.120241Z"
    }
   },
   "source": [
    "# calculate cf_def\n",
    "\n",
    "def calculate_part1_cf_def(row):\n",
    "    return (row['fielding_ratings_outfield_arm'] * -0.000190034965) + 4.665287879\n",
    "\n",
    "def calculate_part2_cf_def(row):\n",
    "    if row['fielding_ratings_outfield_range'] <= 80:\n",
    "        return (row['fielding_ratings_outfield_range'] * 0) + 4.86\n",
    "    else:\n",
    "        return (row['fielding_ratings_outfield_range'] * -0.0030625) + 5.15075\n",
    "\n",
    "def calculate_part3_cf_def(row):\n",
    "    return (row['fielding_ratings_outfield_error'] * -0.0001664335664) + 4.659636364\n",
    "\n",
    "merged_df['part1_cf_def'] = merged_df.apply(calculate_part1_cf_def, axis=1)\n",
    "merged_df['part2_cf_def'] = merged_df.apply(calculate_part2_cf_def, axis=1)\n",
    "merged_df['part3_cf_def'] = merged_df.apply(calculate_part3_cf_def, axis=1)\n",
    "\n",
    "merged_df['cf_def'] = 4.6385 - merged_df['part1_cf_def'] + 4.6385 - merged_df['part2_cf_def'] + 4.6385 - merged_df['part3_cf_def']\n",
    "\n",
    "# Drop the intermediate calculations from the dataframe\n",
    "merged_df = merged_df.drop(columns=['part1_cf_def', 'part2_cf_def', 'part3_cf_def'])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3307182699.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part1_cf_def'] = merged_df.apply(calculate_part1_cf_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3307182699.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part2_cf_def'] = merged_df.apply(calculate_part2_cf_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3307182699.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part3_cf_def'] = merged_df.apply(calculate_part3_cf_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3307182699.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['cf_def'] = 4.6385 - merged_df['part1_cf_def'] + 4.6385 - merged_df['part2_cf_def'] + 4.6385 - merged_df['part3_cf_def']\n"
     ]
    }
   ],
   "execution_count": 265
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:24.680285Z",
     "start_time": "2025-03-25T04:00:24.391022Z"
    }
   },
   "source": [
    "# calculate rf_def\n",
    "\n",
    "def calculate_part1_rf_def(row):\n",
    "    if row['fielding_ratings_outfield_arm'] <= 60:\n",
    "        return (row['fielding_ratings_outfield_arm'] * 0) + 4.683\n",
    "    elif 61 <= row['fielding_ratings_outfield_arm'] <= 180:\n",
    "        return (row['fielding_ratings_outfield_arm'] * -0.0005428571429) + 4.716142857\n",
    "    else:\n",
    "        return (row['fielding_ratings_outfield_arm'] * 0) + 4.618\n",
    "\n",
    "def calculate_part2_rf_def(row):\n",
    "    if row['fielding_ratings_outfield_range'] <= 80:\n",
    "        return (row['fielding_ratings_outfield_range'] * -0.000455) + 4.89\n",
    "    elif 81 <= row['fielding_ratings_outfield_range'] <= 160:\n",
    "        return (row['fielding_ratings_outfield_range'] * -0.004385) + 5.1866\n",
    "    else:\n",
    "        return (row['fielding_ratings_outfield_range'] * 0) + 4.5\n",
    "\n",
    "def calculate_part3_rf_def(row):\n",
    "    return (row['fielding_ratings_outfield_error'] * 0) + 4.6385\n",
    "\n",
    "merged_df['part1_rf_def'] = merged_df.apply(calculate_part1_rf_def, axis=1)\n",
    "merged_df['part2_rf_def'] = merged_df.apply(calculate_part2_rf_def, axis=1)\n",
    "merged_df['part3_rf_def'] = merged_df.apply(calculate_part3_rf_def, axis=1)\n",
    "\n",
    "merged_df['rf_def'] = 4.6385 - merged_df['part1_rf_def'] + 4.6385 - merged_df['part2_rf_def'] + 4.6385 - merged_df['part3_rf_def']\n",
    "\n",
    "# Drop the intermediate calculations from the dataframe\n",
    "merged_df = merged_df.drop(columns=['part1_rf_def', 'part2_rf_def', 'part3_rf_def'])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3156914341.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part1_rf_def'] = merged_df.apply(calculate_part1_rf_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3156914341.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part2_rf_def'] = merged_df.apply(calculate_part2_rf_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3156914341.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part3_rf_def'] = merged_df.apply(calculate_part3_rf_def, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3156914341.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['rf_def'] = 4.6385 - merged_df['part1_rf_def'] + 4.6385 - merged_df['part2_rf_def'] + 4.6385 - merged_df['part3_rf_def']\n"
     ]
    }
   ],
   "execution_count": 266
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:24.702355Z",
     "start_time": "2025-03-25T04:00:24.694139Z"
    }
   },
   "source": [
    "# calculate defensive WAR (tdWAR) for each position\n",
    "merged_df['c_tdWAR'] = ((merged_df['c_def'] * 162) / 10) + 1.5\n",
    "merged_df['1b_tdWAR'] = ((merged_df['1b_def'] * 162) / 10) + 0.5\n",
    "merged_df['2b_tdWAR'] = ((merged_df['2b_def'] * 162) / 10) + 1.75\n",
    "merged_df['3b_tdWAR'] = ((merged_df['3b_def'] * 162) / 10) + 1.8\n",
    "merged_df['ss_tdWAR'] = ((merged_df['ss_def'] * 162) / 10) + 2\n",
    "merged_df['lf_tdWAR'] = ((merged_df['lf_def'] * 162) / 10) + 0.3\n",
    "merged_df['cf_tdWAR'] = ((merged_df['cf_def'] * 162) / 10) + 2.5\n",
    "merged_df['rf_tdWAR'] = ((merged_df['rf_def'] * 162) / 10) + 0.6\n",
    "merged_df['dh_tdWAR'] = 0"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\191607530.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['c_tdWAR'] = ((merged_df['c_def'] * 162) / 10) + 1.5\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\191607530.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['1b_tdWAR'] = ((merged_df['1b_def'] * 162) / 10) + 0.5\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\191607530.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['2b_tdWAR'] = ((merged_df['2b_def'] * 162) / 10) + 1.75\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\191607530.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['3b_tdWAR'] = ((merged_df['3b_def'] * 162) / 10) + 1.8\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\191607530.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['ss_tdWAR'] = ((merged_df['ss_def'] * 162) / 10) + 2\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\191607530.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['lf_tdWAR'] = ((merged_df['lf_def'] * 162) / 10) + 0.3\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\191607530.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['cf_tdWAR'] = ((merged_df['cf_def'] * 162) / 10) + 2.5\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\191607530.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['rf_tdWAR'] = ((merged_df['rf_def'] * 162) / 10) + 0.6\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\191607530.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['dh_tdWAR'] = 0\n"
     ]
    }
   ],
   "execution_count": 267
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:24.722948Z",
     "start_time": "2025-03-25T04:00:24.717264Z"
    }
   },
   "source": [
    "# calculate standardised WAR (sWAR) at each position\n",
    "merged_df['c_sWAR'] = merged_df['toWAR'] + merged_df['c_tdWAR']\n",
    "merged_df['1b_sWAR'] = merged_df['toWAR'] + merged_df['1b_tdWAR']\n",
    "merged_df['2b_sWAR'] = merged_df['toWAR'] + merged_df['2b_tdWAR']\n",
    "merged_df['3b_sWAR'] = merged_df['toWAR'] + merged_df['3b_tdWAR']\n",
    "merged_df['ss_sWAR'] = merged_df['toWAR'] + merged_df['ss_tdWAR']\n",
    "merged_df['lf_sWAR'] = merged_df['toWAR'] + merged_df['lf_tdWAR']\n",
    "merged_df['cf_sWAR'] = merged_df['toWAR'] + merged_df['cf_tdWAR']\n",
    "merged_df['rf_sWAR'] = merged_df['toWAR'] + merged_df['rf_tdWAR']\n",
    "merged_df['dh_sWAR'] = merged_df['toWAR'] + merged_df['dh_tdWAR']"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3786733410.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['c_sWAR'] = merged_df['toWAR'] + merged_df['c_tdWAR']\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3786733410.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['1b_sWAR'] = merged_df['toWAR'] + merged_df['1b_tdWAR']\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3786733410.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['2b_sWAR'] = merged_df['toWAR'] + merged_df['2b_tdWAR']\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3786733410.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['3b_sWAR'] = merged_df['toWAR'] + merged_df['3b_tdWAR']\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3786733410.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['ss_sWAR'] = merged_df['toWAR'] + merged_df['ss_tdWAR']\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3786733410.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['lf_sWAR'] = merged_df['toWAR'] + merged_df['lf_tdWAR']\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3786733410.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['cf_sWAR'] = merged_df['toWAR'] + merged_df['cf_tdWAR']\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3786733410.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['rf_sWAR'] = merged_df['toWAR'] + merged_df['rf_tdWAR']\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3786733410.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['dh_sWAR'] = merged_df['toWAR'] + merged_df['dh_tdWAR']\n"
     ]
    }
   ],
   "execution_count": 268
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:24.749085Z",
     "start_time": "2025-03-25T04:00:24.739369Z"
    }
   },
   "source": [
    "# calculate the best value of sWAR across all the positions for each player\n",
    "merged_df['best_sWAR'] = merged_df[['c_sWAR', '1b_sWAR', '2b_sWAR', '3b_sWAR', 'ss_sWAR', 'lf_sWAR', 'cf_sWAR', 'rf_sWAR', 'dh_sWAR']].max(axis=1)\n",
    "\n",
    "# add a column to say which position the player should play based on the best value of sWAR (remove the (_sWAR) part of the column name)\n",
    "merged_df['best_sWAR_pos'] = merged_df[['c_sWAR', '1b_sWAR', '2b_sWAR', '3b_sWAR', 'ss_sWAR', 'lf_sWAR', 'cf_sWAR', 'rf_sWAR', 'dh_sWAR']].idxmax(axis=1).str.replace('_sWAR', '')\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2391967965.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['best_sWAR'] = merged_df[['c_sWAR', '1b_sWAR', '2b_sWAR', '3b_sWAR', 'ss_sWAR', 'lf_sWAR', 'cf_sWAR', 'rf_sWAR', 'dh_sWAR']].max(axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2391967965.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['best_sWAR_pos'] = merged_df[['c_sWAR', '1b_sWAR', '2b_sWAR', '3b_sWAR', 'ss_sWAR', 'lf_sWAR', 'cf_sWAR', 'rf_sWAR', 'dh_sWAR']].idxmax(axis=1).str.replace('_sWAR', '')\n"
     ]
    }
   ],
   "execution_count": 269
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:24.774715Z",
     "start_time": "2025-03-25T04:00:24.769100Z"
    }
   },
   "source": [
    "# merge first name and last name into a column called name \n",
    "merged_df['name'] = merged_df['first_name'] + \" \" + merged_df['last_name']"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\4114809170.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['name'] = merged_df['first_name'] + \" \" + merged_df['last_name']\n"
     ]
    }
   ],
   "execution_count": 270
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:24.899892Z",
     "start_time": "2025-03-25T04:00:24.799388Z"
    }
   },
   "source": [
    "# following cells recalculate the MOPS methodology for all batters, but using talent not overall ratings\n",
    "\n",
    "# add new function to calculate bb%_potential\n",
    "def calculate_bb_pot(row):\n",
    "    if row['batting_ratings_talent_eye'] <= 100:\n",
    "        return ((row['batting_ratings_talent_eye'] * 0.0007268758188) + 0.001460739)\n",
    "    elif row['batting_ratings_talent_eye'] >= 101:\n",
    "        return ((row['batting_ratings_talent_eye'] * 0.0012280964) - 0.0469974639)\n",
    "\n",
    "merged_df['bb%_pot'] = merged_df.apply(calculate_bb_pot, axis=1)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3305448036.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['bb%_pot'] = merged_df.apply(calculate_bb_pot, axis=1)\n"
     ]
    }
   ],
   "execution_count": 271
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:25.003447Z",
     "start_time": "2025-03-25T04:00:24.913215Z"
    }
   },
   "source": [
    "# k%_potential (using the same 'fudge factor' adjustments as for k%)\n",
    "def calculate_k_pot(row):\n",
    "    # Cap batting_ratings_talent_strikeouts at 180\n",
    "    strikeouts = min(row['batting_ratings_talent_strikeouts'], 180)\n",
    "\n",
    "    # Adjusted strikeouts calculation\n",
    "    adjusted_strikeouts = strikeouts + ((100 - strikeouts) * 0.1)\n",
    "\n",
    "    # Apply formula based on strikeout level\n",
    "    if strikeouts <= 100:\n",
    "        return (adjusted_strikeouts * -0.002454367) + 0.4655792299\n",
    "    elif 101 <= strikeouts <= 220:\n",
    "        return (adjusted_strikeouts * -0.0016592514) + 0.383395059\n",
    "    else:\n",
    "        return (adjusted_strikeouts * 0) + 0.02385\n",
    "\n",
    "# Apply function to calculate 'k%_pot'\n",
    "merged_df['k%_pot'] = merged_df.apply(calculate_k_pot, axis=1)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1992980315.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['k%_pot'] = merged_df.apply(calculate_k_pot, axis=1)\n"
     ]
    }
   ],
   "execution_count": 272
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:25.118264Z",
     "start_time": "2025-03-25T04:00:25.017823Z"
    }
   },
   "source": [
    "# calculate hr%_potential\n",
    "def calculate_hr_pot(row):\n",
    "    if row['batting_ratings_talent_power'] <= 100:\n",
    "        return (row['batting_ratings_talent_power'] * 0.0001965717055) + 0.0057097943\n",
    "    elif row['batting_ratings_talent_power'] > 100:\n",
    "        return (row['batting_ratings_talent_power'] * 0.0005767110238) - 0.0305087264\n",
    "\n",
    "merged_df['hr%_pot'] = merged_df.apply(calculate_hr_pot, axis=1)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2714845023.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['hr%_pot'] = merged_df.apply(calculate_hr_pot, axis=1)\n"
     ]
    }
   ],
   "execution_count": 273
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:25.440551Z",
     "start_time": "2025-03-25T04:00:25.131579Z"
    }
   },
   "source": [
    "# calculate 2b% potential with same fudge factor adjustment as 2b%\n",
    "def calculate_part1_2b_pot(row):\n",
    "    # Reduce impact by adjusting the distance to 100 (multiplying by 0.6666 instead of direct value)\n",
    "    adjusted_gap = row['batting_ratings_talent_gap'] - ((row['batting_ratings_talent_gap'] - 100) * 0.6666)\n",
    "    return (adjusted_gap * 0.0005759923464) + 0.0046460781\n",
    "\n",
    "# Function to calculate part2_2b_pot\n",
    "def calculate_part2_2b_pot(row):\n",
    "    if row['batting_ratings_talent_power'] <= 100:\n",
    "        return (row['batting_ratings_talent_power'] * -0.0000508547503) + 0.0669597896 - 0.0628\n",
    "    else:\n",
    "        return (row['batting_ratings_talent_power'] * -0.00008542726043) + 0.071154717 - 0.0628\n",
    "\n",
    "# Function to calculate part3_2b_pot\n",
    "def calculate_part3_2b_pot(row):\n",
    "    if row['batting_ratings_talent_strikeouts'] <= 100:\n",
    "        return (row['batting_ratings_talent_strikeouts'] * -0.0002084865135) + 0.0828934273 - 0.0628\n",
    "    elif 101 <= row['batting_ratings_talent_strikeouts'] <= 220:\n",
    "        return (row['batting_ratings_talent_strikeouts'] * -0.000008259599351) + 0.0708287518 - 0.0628\n",
    "    else:\n",
    "        return (row['batting_ratings_talent_strikeouts'] * 0) + 0.053 - 0.0628\n",
    "\n",
    "# Apply calculations to dataframe\n",
    "merged_df['part1_2b_pot'] = merged_df.apply(calculate_part1_2b_pot, axis=1)\n",
    "merged_df['part2_2b_pot'] = merged_df.apply(calculate_part2_2b_pot, axis=1)\n",
    "merged_df['part3_2b_pot'] = merged_df.apply(calculate_part3_2b_pot, axis=1)\n",
    "\n",
    "# Compute final 2b%_pot value\n",
    "merged_df['2b%_pot'] = merged_df['part1_2b_pot'] + merged_df['part2_2b_pot'] + merged_df['part3_2b_pot']\n",
    "\n",
    "# Drop the intermediate calculations from the dataframe\n",
    "merged_df = merged_df.drop(columns=['part1_2b_pot', 'part2_2b_pot', 'part3_2b_pot'])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2050699166.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part1_2b_pot'] = merged_df.apply(calculate_part1_2b_pot, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2050699166.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part2_2b_pot'] = merged_df.apply(calculate_part2_2b_pot, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2050699166.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part3_2b_pot'] = merged_df.apply(calculate_part3_2b_pot, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2050699166.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['2b%_pot'] = merged_df['part1_2b_pot'] + merged_df['part2_2b_pot'] + merged_df['part3_2b_pot']\n"
     ]
    }
   ],
   "execution_count": 274
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:25.759381Z",
     "start_time": "2025-03-25T04:00:25.453336Z"
    }
   },
   "source": [
    "# calculate 3b%_potential\n",
    "\n",
    "def calculate_part1_3b_pot(row):\n",
    "    return (row['batting_ratings_talent_gap'] * 0.00004451978242) + 0.00007767274633\n",
    "\n",
    "def calculate_part2_3b_pot(row):\n",
    "    if row['batting_ratings_talent_power'] <= 100:\n",
    "        return (row['batting_ratings_talent_power'] * -0.00000206286281) + 0.0046134367 - 0.0044\n",
    "    else:\n",
    "        return (row['batting_ratings_talent_power'] * -0.000007041275071) + 0.0051236727 - 0.0044\n",
    "\n",
    "def calculate_part3_3b_pot(row):\n",
    "    if row['batting_ratings_talent_strikeouts'] <= 100:\n",
    "        return (row['batting_ratings_talent_strikeouts'] * -0.00001098275967) + 0.0055735013 - 0.0044\n",
    "    elif 101 <= row['batting_ratings_talent_strikeouts'] <= 220:\n",
    "        return (row['batting_ratings_talent_strikeouts'] * -0.00000526736139) + 0.0048976614 - 0.0044\n",
    "    else:\n",
    "        return (row['batting_ratings_talent_strikeouts'] * 0) + 0.0037 - 0.0044\n",
    "\n",
    "merged_df['part1_3b_pot'] = merged_df.apply(calculate_part1_3b_pot, axis=1)\n",
    "merged_df['part2_3b_pot'] = merged_df.apply(calculate_part2_3b_pot, axis=1)\n",
    "merged_df['part3_3b_pot'] = merged_df.apply(calculate_part3_3b_pot, axis=1)\n",
    "\n",
    "merged_df['3b%_pot'] = merged_df['part1_3b_pot'] + merged_df['part2_3b_pot'] + merged_df['part3_3b_pot']\n",
    "\n",
    "# Drop the intermediate calculations from the dataframe\n",
    "merged_df = merged_df.drop(columns=['part1_3b_pot', 'part2_3b_pot', 'part3_3b_pot'])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1034148351.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part1_3b_pot'] = merged_df.apply(calculate_part1_3b_pot, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1034148351.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part2_3b_pot'] = merged_df.apply(calculate_part2_3b_pot, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1034148351.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part3_3b_pot'] = merged_df.apply(calculate_part3_3b_pot, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1034148351.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['3b%_pot'] = merged_df['part1_3b_pot'] + merged_df['part2_3b_pot'] + merged_df['part3_3b_pot']\n"
     ]
    }
   ],
   "execution_count": 275
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:26.063480Z",
     "start_time": "2025-03-25T04:00:25.771656Z"
    }
   },
   "source": [
    "# calculate 1b%_pot\n",
    "\n",
    "def calculate_part1_1b_pot(row):\n",
    "    if row['batting_ratings_talent_babip'] <= 100:\n",
    "        return (row['batting_ratings_talent_babip'] * 0.0015140038) + 0.1281801944\n",
    "    else:\n",
    "        return (row['batting_ratings_talent_babip'] * 0.000964994955) + 0.1837822012\n",
    "\n",
    "def calculate_part2_1b_pot(row):\n",
    "    return (row['batting_ratings_talent_gap'] * -0.0003887320573) + 0.3178756912 - 0.28\n",
    "\n",
    "def calculate_part3_1b_pot(row):\n",
    "    if row['batting_ratings_talent_strikeouts'] <= 100:\n",
    "        return (row['batting_ratings_talent_strikeouts'] * 0.000149985378) + 0.2648525907 - 0.28\n",
    "    elif 101 <= row['batting_ratings_talent_strikeouts'] <= 220:\n",
    "        return (row['batting_ratings_talent_strikeouts'] * 0.00005179135613) + 0.2754044069 - 0.28\n",
    "    else:\n",
    "        return (row['batting_ratings_talent_strikeouts'] * 0) + 0.286 - 0.28\n",
    "\n",
    "merged_df['part1_1b_pot'] = merged_df.apply(calculate_part1_1b_pot, axis=1)\n",
    "merged_df['part2_1b_pot'] = merged_df.apply(calculate_part2_1b_pot, axis=1)\n",
    "merged_df['part3_1b_pot'] = merged_df.apply(calculate_part3_1b_pot, axis=1)\n",
    "\n",
    "merged_df['1b%_pot'] = merged_df['part1_1b_pot'] + merged_df['part2_1b_pot'] + merged_df['part3_1b_pot']"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1970547978.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part1_1b_pot'] = merged_df.apply(calculate_part1_1b_pot, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1970547978.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part2_1b_pot'] = merged_df.apply(calculate_part2_1b_pot, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1970547978.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['part3_1b_pot'] = merged_df.apply(calculate_part3_1b_pot, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1970547978.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['1b%_pot'] = merged_df['part1_1b_pot'] + merged_df['part2_1b_pot'] + merged_df['part3_1b_pot']\n"
     ]
    }
   ],
   "execution_count": 276
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:26.081427Z",
     "start_time": "2025-03-25T04:00:26.077340Z"
    }
   },
   "source": [
    "# calculate Offensive Runs Created Potential per game (orc_per_game_pot)\n",
    "merged_df['orc_per_game_pot'] = ((merged_df['bb%_pot'] - 0.0738) / 0.875) + ((merged_df['k%_pot'] - 0.2195) / -1.217) + ((merged_df['hr%_pot'] - 0.0272) / 0.219) + ((merged_df['2b%_pot'] - 0.0628) / 0.693) + ((merged_df['3b%_pot'] - 0.0044) / 0.0519) + ((merged_df['1b%_pot'] - 0.28) / 0.594)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2420540773.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['orc_per_game_pot'] = ((merged_df['bb%_pot'] - 0.0738) / 0.875) + ((merged_df['k%_pot'] - 0.2195) / -1.217) + ((merged_df['hr%_pot'] - 0.0272) / 0.219) + ((merged_df['2b%_pot'] - 0.0628) / 0.693) + ((merged_df['3b%_pot'] - 0.0044) / 0.0519) + ((merged_df['1b%_pot'] - 0.28) / 0.594)\n"
     ]
    }
   ],
   "execution_count": 277
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:26.105082Z",
     "start_time": "2025-03-25T04:00:26.101478Z"
    }
   },
   "source": [
    "# calculate offensive WAR potential\n",
    "merged_df['toWAR_pot'] = (merged_df['orc_per_game_pot'] * 162) / 10"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1927707568.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['toWAR_pot'] = (merged_df['orc_per_game_pot'] * 162) / 10\n"
     ]
    }
   ],
   "execution_count": 278
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:26.132818Z",
     "start_time": "2025-03-25T04:00:26.127134Z"
    }
   },
   "source": [
    "# calculate standardised WAR potential (sWAR_pot) at each position\n",
    "merged_df['c_sWAR_pot'] = merged_df['toWAR_pot'] + merged_df['c_tdWAR']\n",
    "merged_df['1b_sWAR_pot'] = merged_df['toWAR_pot'] + merged_df['1b_tdWAR']\n",
    "merged_df['2b_sWAR_pot'] = merged_df['toWAR_pot'] + merged_df['2b_tdWAR']\n",
    "merged_df['3b_sWAR_pot'] = merged_df['toWAR_pot'] + merged_df['3b_tdWAR']\n",
    "merged_df['ss_sWAR_pot'] = merged_df['toWAR_pot'] + merged_df['ss_tdWAR']\n",
    "merged_df['lf_sWAR_pot'] = merged_df['toWAR_pot'] + merged_df['lf_tdWAR']\n",
    "merged_df['cf_sWAR_pot'] = merged_df['toWAR_pot'] + merged_df['cf_tdWAR']\n",
    "merged_df['rf_sWAR_pot'] = merged_df['toWAR_pot'] + merged_df['rf_tdWAR']\n",
    "merged_df['dh_sWAR_pot'] = merged_df['toWAR_pot'] + merged_df['dh_tdWAR']"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3622890623.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['c_sWAR_pot'] = merged_df['toWAR_pot'] + merged_df['c_tdWAR']\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3622890623.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['1b_sWAR_pot'] = merged_df['toWAR_pot'] + merged_df['1b_tdWAR']\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3622890623.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['2b_sWAR_pot'] = merged_df['toWAR_pot'] + merged_df['2b_tdWAR']\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3622890623.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['3b_sWAR_pot'] = merged_df['toWAR_pot'] + merged_df['3b_tdWAR']\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3622890623.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['ss_sWAR_pot'] = merged_df['toWAR_pot'] + merged_df['ss_tdWAR']\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3622890623.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['lf_sWAR_pot'] = merged_df['toWAR_pot'] + merged_df['lf_tdWAR']\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3622890623.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['cf_sWAR_pot'] = merged_df['toWAR_pot'] + merged_df['cf_tdWAR']\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3622890623.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['rf_sWAR_pot'] = merged_df['toWAR_pot'] + merged_df['rf_tdWAR']\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3622890623.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['dh_sWAR_pot'] = merged_df['toWAR_pot'] + merged_df['dh_tdWAR']\n"
     ]
    }
   ],
   "execution_count": 279
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:26.169733Z",
     "start_time": "2025-03-25T04:00:26.155875Z"
    }
   },
   "source": [
    "# calculate the best value of sWAR_pot across all the positions for each player\n",
    "merged_df['best_sWAR_pot'] = merged_df[['c_sWAR_pot', '1b_sWAR_pot', '2b_sWAR_pot', '3b_sWAR_pot', 'ss_sWAR_pot', 'lf_sWAR_pot', 'cf_sWAR_pot', 'rf_sWAR_pot', 'dh_sWAR_pot']].max(axis=1)\n",
    "\n",
    "# add a column to say which position the player should play based on the best value of sWAR (remove the (_sWAR) part of the column name)\n",
    "merged_df['best_sWAR_pot_pos'] = merged_df[['c_sWAR_pot', '1b_sWAR_pot', '2b_sWAR_pot', '3b_sWAR_pot', 'ss_sWAR_pot', 'lf_sWAR_pot', 'cf_sWAR_pot', 'rf_sWAR_pot', 'dh_sWAR_pot']].idxmax(axis=1).str.replace('_sWAR', '')\n",
    "\n",
    "print(merged_df.head())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   player_id  team_id  league_id  position  role first_name    last_name  age  \\\n",
      "0          2        0          0         3     0       John     Nogowski   32   \n",
      "1          3        0          0         4     0    Patrick      Dorrian   28   \n",
      "2          6       18        203         1    11     Carlos        Rodón   32   \n",
      "3          7      270        210         4     0     George  Lombard Jr.   19   \n",
      "4          8        0          0         1    11    Brandon     Finnegan   31   \n",
      "\n",
      "  date_of_birth  weight  ...  1b_sWAR_pot  2b_sWAR_pot  3b_sWAR_pot  \\\n",
      "0      1993-1-5     229  ...     0.092258    -1.849105    -0.883716   \n",
      "1     1996-6-26     187  ...    -1.395358    -1.869213    -2.158366   \n",
      "2    1992-12-10     236  ...    -8.680271   -12.866959   -11.745741   \n",
      "3      2005-6-2     192  ...     1.408748     1.191348     0.226867   \n",
      "4     1993-4-14     213  ...    -9.530371   -12.983806   -13.211899   \n",
      "\n",
      "   ss_sWAR_pot  lf_sWAR_pot  cf_sWAR_pot  rf_sWAR_pot  dh_sWAR_pot  \\\n",
      "0    -5.726258     0.618101    -1.197702    -1.691070    -0.216996   \n",
      "1    -6.034421    -4.710896    -3.817739    -4.521784    -1.911118   \n",
      "2   -16.179110   -13.012782   -10.386903   -12.199514    -9.029126   \n",
      "3    -1.831710     1.700646     0.605618     0.274615     0.752806   \n",
      "4   -17.496329   -14.134593   -11.270098   -13.544415    -9.607200   \n",
      "\n",
      "   best_sWAR_pot  best_sWAR_pot_pos  \n",
      "0       0.618101             lf_pot  \n",
      "1      -1.395358             1b_pot  \n",
      "2      -8.680271             1b_pot  \n",
      "3       1.700646             lf_pot  \n",
      "4      -9.530371             1b_pot  \n",
      "\n",
      "[5 rows x 283 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2732519938.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['best_sWAR_pot'] = merged_df[['c_sWAR_pot', '1b_sWAR_pot', '2b_sWAR_pot', '3b_sWAR_pot', 'ss_sWAR_pot', 'lf_sWAR_pot', 'cf_sWAR_pot', 'rf_sWAR_pot', 'dh_sWAR_pot']].max(axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2732519938.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['best_sWAR_pot_pos'] = merged_df[['c_sWAR_pot', '1b_sWAR_pot', '2b_sWAR_pot', '3b_sWAR_pot', 'ss_sWAR_pot', 'lf_sWAR_pot', 'cf_sWAR_pot', 'rf_sWAR_pot', 'dh_sWAR_pot']].idxmax(axis=1).str.replace('_sWAR', '')\n"
     ]
    }
   ],
   "execution_count": 280
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:27.209945Z",
     "start_time": "2025-03-25T04:00:26.193331Z"
    }
   },
   "source": [
    "# calculated modified best position based on fielding ratings - i.e. whether a hitter 'has a position' or is just a 1b/dh\n",
    "\n",
    "def determine_positions(row):\n",
    "    positions = []  # List to store all eligible positions\n",
    "\n",
    "    # Apply position rules\n",
    "    if row['fielding_ratings_catcher_framing'] >= 150:\n",
    "        positions.append('C')\n",
    "    if row['fielding_ratings_infield_range'] > 160:\n",
    "        positions.append('SS')\n",
    "    if 133 < row['fielding_ratings_infield_range'] < 159:\n",
    "        positions.append('2B')\n",
    "    if row['fielding_ratings_infield_range'] > 111 and row['fielding_ratings_infield_arm'] > 133:\n",
    "        positions.append('3B')\n",
    "    if row['fielding_ratings_outfield_range'] > 160:\n",
    "        positions.append('CF')\n",
    "    if 133 < row['fielding_ratings_outfield_range'] < 159:\n",
    "        positions.append('RF')\n",
    "    if 111 < row['fielding_ratings_outfield_range'] < 133:\n",
    "        positions.append('LF')\n",
    "\n",
    "    # Determine 'has_pos' column (yes if qualified for any position, else blank)\n",
    "    has_pos = \"yes\" if positions else \"\"\n",
    "\n",
    "    # Convert list of positions into a string (comma-separated)\n",
    "    field_positions = \", \".join(positions) if positions else \"\"\n",
    "\n",
    "    return pd.Series([has_pos, field_positions])\n",
    "\n",
    "# Apply function to dataframe\n",
    "merged_df[['has_pos', 'field']] = merged_df.apply(determine_positions, axis=1)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3764069052.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[['has_pos', 'field']] = merged_df.apply(determine_positions, axis=1)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3764069052.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[['has_pos', 'field']] = merged_df.apply(determine_positions, axis=1)\n"
     ]
    }
   ],
   "execution_count": 281
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:27.585217Z",
     "start_time": "2025-03-25T04:00:27.279099Z"
    }
   },
   "source": [
    "# determining how many pitches with rating over 45 (on 20-80 scale; equivalent to 85 on 0-250 scale) a pitcher has\n",
    "# the pitch quality threshold in OOTP 24 was 50; this has been lowered to 45 for OOTP 26 as pitch ratings look lower (1-250 scale 45 = 85, 50 = 101 as per above THIS MAY CHANGE)\n",
    "pitch_minimum_rating = 85\n",
    "pitch_columns = ['pitching_ratings_pitches_fastball', 'pitching_ratings_pitches_slider', 'pitching_ratings_pitches_curveball', 'pitching_ratings_pitches_screwball', 'pitching_ratings_pitches_forkball', 'pitching_ratings_pitches_changeup', 'pitching_ratings_pitches_sinker', 'pitching_ratings_pitches_splitter', 'pitching_ratings_pitches_knuckleball', 'pitching_ratings_pitches_cutter', 'pitching_ratings_pitches_circlechange', 'pitching_ratings_pitches_knucklecurve']\n",
    "merged_df['no_of_pitches'] = merged_df[pitch_columns].apply(lambda row: sum(row >= pitch_minimum_rating), axis=1)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\615868934.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['no_of_pitches'] = merged_df[pitch_columns].apply(lambda row: sum(row >= pitch_minimum_rating), axis=1)\n"
     ]
    }
   ],
   "execution_count": 282
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:27.667205Z",
     "start_time": "2025-03-25T04:00:27.663127Z"
    }
   },
   "source": [
    "# determining whether a pitcher is a starter (NB needs to be a groundball pitcher with stamina >= 40 on 20-80 scale and at least 3 pitches)\n",
    "# new threshold added for OOTP 26 of pbabip >= 45\n",
    "merged_df['is_sp'] = ((merged_df['pitching_ratings_misc_ground_fly'] >= min_gb) &\n",
    "                      (merged_df['pitching_ratings_misc_stamina'] >= 68) &\n",
    "                      (merged_df['pbabip2080'] >= 45) &\n",
    "                      (merged_df['no_of_pitches'] >= 3))\n",
    "merged_df['is_sp'] = merged_df['is_sp'].astype(int)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3996139685.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['is_sp'] = ((merged_df['pitching_ratings_misc_ground_fly'] >= min_gb) &\n"
     ]
    }
   ],
   "execution_count": 283
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:27.687732Z",
     "start_time": "2025-03-25T04:00:27.683630Z"
    }
   },
   "source": [
    "# determining whether a pitcher is a reliever (NB needs to have at least 2 pitches and be a groundball pitcher, and not a starter as defined above)\n",
    "# new threshold added for OOTP 26 of pbabip >= 45\n",
    "merged_df['is_rp'] = ((merged_df['pitching_ratings_misc_ground_fly'] >= min_gb) & \n",
    "                      (merged_df['no_of_pitches'] >= 2) & \n",
    "                      (merged_df['pbabip2080'] >= 45) &\n",
    "                      (merged_df['is_sp'] == 0))\n",
    "merged_df['is_rp'] = merged_df['is_rp'].astype(int)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2556986027.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['is_rp'] = ((merged_df['pitching_ratings_misc_ground_fly'] >= min_gb) &\n"
     ]
    }
   ],
   "execution_count": 284
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:27.721625Z",
     "start_time": "2025-03-25T04:00:27.718047Z"
    }
   },
   "source": [
    "# halve ratings for use in Donkeykong FIP calculation which is on a 1-125 scale\n",
    "merged_df['donkeykong_stuff'] = merged_df['pitching_ratings_overall_stuff'] / 2\n",
    "merged_df['donkeykong_control'] = merged_df['pitching_ratings_overall_control'] / 2\n",
    "merged_df['donkeykong_movement'] = merged_df['pitching_ratings_overall_movement'] / 2"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2758762120.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['donkeykong_stuff'] = merged_df['pitching_ratings_overall_stuff'] / 2\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2758762120.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['donkeykong_control'] = merged_df['pitching_ratings_overall_control'] / 2\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2758762120.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['donkeykong_movement'] = merged_df['pitching_ratings_overall_movement'] / 2\n"
     ]
    }
   ],
   "execution_count": 285
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:27.762705Z",
     "start_time": "2025-03-25T04:00:27.757587Z"
    }
   },
   "source": [
    "# preserve here the 'donkeykong FIP' used in prior versions of pistachio\n",
    "merged_df['donkeyFIP'] = 8.661141 - (0.01747 * merged_df['donkeykong_stuff']) - (0.03291 * merged_df['donkeykong_movement']) - (0.01737 * merged_df['donkeykong_control'])\n",
    "\n",
    "# calculate FIP projection for each pitcher based on v2 weightings (22% stuff, 22% control, 51% home run allowed, 5% pbabip)\n",
    "# first calculate blended pitcher rating\n",
    "# then map onto FIP scale (roughly so that blended pitcher ratings of 65, 50 and 45 correspond to FIP- of 70, 100 and 130 and FIP of 2.75, 4.1 and 5.45 respectively)\n",
    "# assumes league average FIP is 4.1, and a league-leading FIP is about 2.75\n",
    "merged_df['pitcher_rtg'] = ((0.25 * merged_df['stuff2080']) + (0.19 * merged_df['ctrl2080']) + (0.51 * merged_df['hra2080']) + (0.05 * merged_df['pbabip2080']))\n",
    "\n",
    "# FIP is one value when pitcher rating above 50 and another when below\n",
    "merged_df['FIP'] = np.where(\n",
    "    merged_df['pitcher_rtg'] > 50,\n",
    "    4.1 - ((merged_df['pitcher_rtg'] - 50) * ((4.1 - 2.75) / 15)),\n",
    "    4.1 + ((50 - merged_df['pitcher_rtg']) * ((5.45 - 4.1) / 5))\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3677832567.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['donkeyFIP'] = 8.661141 - (0.01747 * merged_df['donkeykong_stuff']) - (0.03291 * merged_df['donkeykong_movement']) - (0.01737 * merged_df['donkeykong_control'])\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3677832567.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['pitcher_rtg'] = ((0.25 * merged_df['stuff2080']) + (0.19 * merged_df['ctrl2080']) + (0.51 * merged_df['hra2080']) + (0.05 * merged_df['pbabip2080']))\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3677832567.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['FIP'] = np.where(\n"
     ]
    }
   ],
   "execution_count": 286
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:27.778704Z",
     "start_time": "2025-03-25T04:00:27.775631Z"
    }
   },
   "source": [
    "# allocate FIP to sp and rp pitchers (starters and relievers)\n",
    "merged_df['sp_FIP'] = merged_df['is_sp'] * merged_df['FIP']\n",
    "merged_df['rp_FIP'] = merged_df['is_rp'] * merged_df['FIP']"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1233563310.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['sp_FIP'] = merged_df['is_sp'] * merged_df['FIP']\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1233563310.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['rp_FIP'] = merged_df['is_rp'] * merged_df['FIP']\n"
     ]
    }
   ],
   "execution_count": 287
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:27.797678Z",
     "start_time": "2025-03-25T04:00:27.793069Z"
    }
   },
   "source": [
    "# calculate starting pitcher standardised WAR from FIP assuming 180 IP (approach per OOTP calculator)\n",
    "\n",
    "# Calculate 'fipr9', 'rpw', and 'sp_sWAR'\n",
    "merged_df['fipr9'] = merged_df['FIP'] + 4.62 - 4.25\n",
    "merged_df['rpw'] = ((((12.375 * 4.62) + (5.625 * merged_df['fipr9'])) / 18) + 2) * 1.5\n",
    "merged_df['p_sWAR'] = (((((4.62-merged_df['fipr9']) / merged_df['rpw']) + 0.12) * 180) / 9)\n",
    "merged_df['sp_sWAR'] = merged_df['p_sWAR'] * merged_df['is_sp']\n",
    "\n",
    "# calculate relief pitcher standardised WAR equal to one-third of sp_sWAR only for pitchers where is_rp is 1\n",
    "merged_df['rp_sWAR'] = (merged_df['p_sWAR'] / 3) * merged_df['is_rp']\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2615729838.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['fipr9'] = merged_df['FIP'] + 4.62 - 4.25\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2615729838.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['rpw'] = ((((12.375 * 4.62) + (5.625 * merged_df['fipr9'])) / 18) + 2) * 1.5\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2615729838.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['p_sWAR'] = (((((4.62-merged_df['fipr9']) / merged_df['rpw']) + 0.12) * 180) / 9)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2615729838.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['sp_sWAR'] = merged_df['p_sWAR'] * merged_df['is_sp']\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2615729838.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['rp_sWAR'] = (merged_df['p_sWAR'] / 3) * merged_df['is_rp']\n"
     ]
    }
   ],
   "execution_count": 288
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:28.097715Z",
     "start_time": "2025-03-25T04:00:27.812038Z"
    }
   },
   "source": [
    "# determining how many pitches a pitcher potentially has based on minimum potential pitch ratings (same logic as for current ratings)\n",
    "pitch_pot_columns = ['pitching_ratings_pitches_talent_fastball', 'pitching_ratings_pitches_talent_slider', 'pitching_ratings_pitches_talent_curveball', 'pitching_ratings_pitches_talent_screwball', 'pitching_ratings_pitches_talent_forkball', 'pitching_ratings_pitches_talent_changeup', 'pitching_ratings_pitches_talent_sinker', 'pitching_ratings_pitches_talent_splitter', 'pitching_ratings_pitches_talent_knuckleball', 'pitching_ratings_pitches_talent_cutter', 'pitching_ratings_pitches_talent_circlechange', 'pitching_ratings_pitches_talent_knucklecurve']\n",
    "merged_df['no_of_pitches_pot'] = merged_df[pitch_pot_columns].apply(lambda row: sum(row >= pitch_minimum_rating), axis=1)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2419486212.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['no_of_pitches_pot'] = merged_df[pitch_pot_columns].apply(lambda row: sum(row >= pitch_minimum_rating), axis=1)\n"
     ]
    }
   ],
   "execution_count": 289
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:28.117235Z",
     "start_time": "2025-03-25T04:00:28.112618Z"
    }
   },
   "source": [
    "# determining whether a pitcher is potentially a starter\n",
    "# new threshold added for OOTP 26 of pbabip potential >= 45\n",
    "merged_df['is_sp_pot'] = ((merged_df['pitching_ratings_misc_ground_fly'] >= min_gb) & \n",
    "                      (merged_df['pitching_ratings_misc_stamina'] >= 69) & \n",
    "                      (merged_df['pbabip2080p'] >= 45) &\n",
    "                      (merged_df['no_of_pitches_pot'] >= 3))\n",
    "merged_df['is_sp_pot'] = merged_df['is_sp_pot'].astype(int)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1012823858.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['is_sp_pot'] = ((merged_df['pitching_ratings_misc_ground_fly'] >= min_gb) &\n"
     ]
    }
   ],
   "execution_count": 290
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:28.133128Z",
     "start_time": "2025-03-25T04:00:28.129546Z"
    }
   },
   "source": [
    "# determining whether a pitcher is potentially a reliever\n",
    "# new threshold added for OOTP 26 of pbabip potential >= 45\n",
    "merged_df['is_rp_pot'] = ((merged_df['pitching_ratings_misc_ground_fly'] >= min_gb) & \n",
    "                      (merged_df['no_of_pitches_pot'] >= 2) &\n",
    "                      (merged_df['pbabip2080p'] >= 45) & \n",
    "                      (merged_df['is_sp_pot'] == 0))\n",
    "merged_df['is_rp_pot'] = merged_df['is_rp_pot'].astype(int)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\838424312.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['is_rp_pot'] = ((merged_df['pitching_ratings_misc_ground_fly'] >= min_gb) &\n"
     ]
    }
   ],
   "execution_count": 291
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:28.149517Z",
     "start_time": "2025-03-25T04:00:28.145429Z"
    }
   },
   "source": [
    "# halve potential ratings for use in Donkeykong FIP calculation which is on a 1-125 scale\n",
    "merged_df['donkeykong_stuff_pot'] = merged_df['pitching_ratings_talent_stuff'] / 2\n",
    "merged_df['donkeykong_control_pot'] = merged_df['pitching_ratings_talent_control'] / 2\n",
    "merged_df['donkeykong_movement_pot'] = merged_df['pitching_ratings_talent_movement'] / 2"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1513164056.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['donkeykong_stuff_pot'] = merged_df['pitching_ratings_talent_stuff'] / 2\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1513164056.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['donkeykong_control_pot'] = merged_df['pitching_ratings_talent_control'] / 2\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1513164056.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['donkeykong_movement_pot'] = merged_df['pitching_ratings_talent_movement'] / 2\n"
     ]
    }
   ],
   "execution_count": 292
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:28.183441Z",
     "start_time": "2025-03-25T04:00:28.178258Z"
    }
   },
   "source": [
    "# preserve here the 'donkeykong FIP' potential used in prior versions of pistachio\n",
    "merged_df['donkeyFIP_pot'] = 8.661141 - (0.01747 * merged_df['donkeykong_stuff_pot']) - (0.03291 * merged_df['donkeykong_movement_pot']) - (0.01737 * merged_df['donkeykong_control_pot'])\n",
    "\n",
    "# calculate blended pitcher rating and FIP projection based on potential in same way as for current ratings\n",
    "merged_df['pitcher_rtg_pot'] = ((0.25 * merged_df['stuff2080p']) + (0.19 * merged_df['ctrl2080p']) + (0.51 * merged_df['hra2080p']) + (0.05 * merged_df['pbabip2080p']))\n",
    "merged_df['FIP_pot'] = np.where(\n",
    "    merged_df['pitcher_rtg_pot'] > 50,\n",
    "    4.1 - ((merged_df['pitcher_rtg_pot'] - 50) * ((4.1 - 2.75) / 15)),\n",
    "    4.1 + ((50 - merged_df['pitcher_rtg_pot']) * ((5.45 - 4.1) / 5))\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2282214893.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['donkeyFIP_pot'] = 8.661141 - (0.01747 * merged_df['donkeykong_stuff_pot']) - (0.03291 * merged_df['donkeykong_movement_pot']) - (0.01737 * merged_df['donkeykong_control_pot'])\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2282214893.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['pitcher_rtg_pot'] = ((0.25 * merged_df['stuff2080p']) + (0.19 * merged_df['ctrl2080p']) + (0.51 * merged_df['hra2080p']) + (0.05 * merged_df['pbabip2080p']))\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2282214893.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['FIP_pot'] = np.where(\n"
     ]
    }
   ],
   "execution_count": 293
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:28.203428Z",
     "start_time": "2025-03-25T04:00:28.199838Z"
    }
   },
   "source": [
    "# allocate potential FIP to potential sp and rp pitchers (starters and relievers)\n",
    "merged_df['sp_FIP_pot'] = merged_df['is_sp_pot'] * merged_df['FIP_pot']\n",
    "merged_df['rp_FIP_pot'] = merged_df['is_rp_pot'] * merged_df['FIP_pot']"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3674911200.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['sp_FIP_pot'] = merged_df['is_sp_pot'] * merged_df['FIP_pot']\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3674911200.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['rp_FIP_pot'] = merged_df['is_rp_pot'] * merged_df['FIP_pot']\n"
     ]
    }
   ],
   "execution_count": 294
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:28.226503Z",
     "start_time": "2025-03-25T04:00:28.221891Z"
    }
   },
   "source": [
    "# calculate potential starting pitcher standardised WAR from FIP assuming 180 IP (approach per OOTP calculator)\n",
    "\n",
    "# Calculate 'fipr9', 'rpw', and 'sp_sWAR'\n",
    "merged_df['fipr9_pot'] = merged_df['FIP_pot'] + 4.62 - 4.25\n",
    "merged_df['rpw_pot'] = ((((12.375 * 4.62) + (5.625 * merged_df['fipr9_pot'])) / 18) + 2) * 1.5\n",
    "merged_df['p_sWAR_pot'] = (((((4.62-merged_df['fipr9_pot']) / merged_df['rpw_pot']) + 0.12) * 180) / 9)\n",
    "merged_df['sp_sWAR_pot'] = merged_df['p_sWAR_pot'] * merged_df['is_sp_pot']\n",
    "\n",
    "# calculate relief pitcher standardised WAR equal to one-third of sp_sWAR only for pitchers where is_rp is 1\n",
    "merged_df['rp_sWAR_pot'] = (merged_df['p_sWAR_pot'] / 3) * merged_df['is_rp_pot']\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3290201515.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['fipr9_pot'] = merged_df['FIP_pot'] + 4.62 - 4.25\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3290201515.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['rpw_pot'] = ((((12.375 * 4.62) + (5.625 * merged_df['fipr9_pot'])) / 18) + 2) * 1.5\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3290201515.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['p_sWAR_pot'] = (((((4.62-merged_df['fipr9_pot']) / merged_df['rpw_pot']) + 0.12) * 180) / 9)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3290201515.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['sp_sWAR_pot'] = merged_df['p_sWAR_pot'] * merged_df['is_sp_pot']\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\3290201515.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['rp_sWAR_pot'] = (merged_df['p_sWAR_pot'] / 3) * merged_df['is_rp_pot']\n"
     ]
    }
   ],
   "execution_count": 295
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:28.255254Z",
     "start_time": "2025-03-25T04:00:28.241377Z"
    }
   },
   "source": [
    "# calculate HRs per 650, OBP and OPS+ for both current and future ratings\n",
    "merged_df['bb650'] = (merged_df['bb%'] * 650)\n",
    "merged_df['hr650'] = (merged_df['hr%'] * ((650 - merged_df['bb650'])))\n",
    "merged_df['k650'] = (merged_df['k%'] * ((650 - merged_df['bb650'])))\n",
    "merged_df['2b'] = (merged_df['2b%'] * ((650 - merged_df['bb650']-merged_df['hr650']-merged_df['k650'])))\n",
    "merged_df['3b'] = (merged_df['3b%'] * ((650 - merged_df['bb650']-merged_df['hr650']-merged_df['k650'])))\n",
    "merged_df['1b'] = (merged_df['1b%'] * ((650 - merged_df['bb650']-merged_df['hr650']-merged_df['k650']-merged_df['2b']-merged_df['3b'])))\n",
    "merged_df['obp'] = ((merged_df['bb650'] + merged_df['hr650'] + merged_df['2b'] + merged_df['3b'] + merged_df['1b']) / 650)\n",
    "merged_df['slg'] = (((merged_df['1b'])+(2*merged_df['2b'])+(3*merged_df['3b'])+(4*merged_df['hr650']))/(650-merged_df['bb650']))\n",
    "merged_df['ops'] = (merged_df['obp']+merged_df['slg'])\n",
    "merged_df['OPS+'] = (((merged_df['ops'])/0.734)*100).round(0)\n",
    "merged_df['HR'] = merged_df['hr650'].round(0)\n",
    "merged_df['OBP'] = merged_df['obp'].round(3)\n",
    "\n",
    "merged_df['bb650_pot'] = (merged_df['bb%_pot'] * 650)\n",
    "merged_df['hr650_pot'] = (merged_df['hr%_pot'] * ((650 - merged_df['bb650_pot'])))\n",
    "merged_df['k650_pot'] = (merged_df['k%_pot'] * ((650 - merged_df['bb650_pot'])))\n",
    "merged_df['2b_pot'] = (merged_df['2b%_pot'] * ((650 - merged_df['bb650_pot']-merged_df['hr650_pot']-merged_df['k650_pot'])))\n",
    "merged_df['3b_pot'] = (merged_df['3b%_pot'] * ((650 - merged_df['bb650_pot']-merged_df['hr650_pot']-merged_df['k650_pot'])))\n",
    "merged_df['1b_pot'] = (merged_df['1b%_pot'] * ((650 - merged_df['bb650_pot']-merged_df['hr650_pot']-merged_df['k650_pot']-merged_df['2b_pot']-merged_df['3b_pot'])))\n",
    "merged_df['obp_pot'] = ((merged_df['bb650_pot'] + merged_df['hr650_pot'] + merged_df['2b_pot'] + merged_df['3b_pot'] + merged_df['1b_pot']) / 650)\n",
    "merged_df['slg_pot'] = (((merged_df['1b_pot'])+(2*merged_df['2b_pot'])+(3*merged_df['3b_pot'])+(4*merged_df['hr650_pot']))/(650-merged_df['bb650_pot']))\n",
    "merged_df['ops_pot'] = (merged_df['obp_pot']+merged_df['slg_pot'])\n",
    "merged_df['OPS+_p'] = (((merged_df['ops_pot'])/0.734)*100).round(0)\n",
    "merged_df['HR_p'] = ((merged_df['hr650_pot'])).round(0)\n",
    "merged_df['OBP_p'] = merged_df['obp_pot'].round(3)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\214028105.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['bb650'] = (merged_df['bb%'] * 650)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\214028105.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['hr650'] = (merged_df['hr%'] * ((650 - merged_df['bb650'])))\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\214028105.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['k650'] = (merged_df['k%'] * ((650 - merged_df['bb650'])))\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\214028105.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['2b'] = (merged_df['2b%'] * ((650 - merged_df['bb650']-merged_df['hr650']-merged_df['k650'])))\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\214028105.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['3b'] = (merged_df['3b%'] * ((650 - merged_df['bb650']-merged_df['hr650']-merged_df['k650'])))\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\214028105.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['1b'] = (merged_df['1b%'] * ((650 - merged_df['bb650']-merged_df['hr650']-merged_df['k650']-merged_df['2b']-merged_df['3b'])))\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\214028105.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['obp'] = ((merged_df['bb650'] + merged_df['hr650'] + merged_df['2b'] + merged_df['3b'] + merged_df['1b']) / 650)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\214028105.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['slg'] = (((merged_df['1b'])+(2*merged_df['2b'])+(3*merged_df['3b'])+(4*merged_df['hr650']))/(650-merged_df['bb650']))\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\214028105.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['ops'] = (merged_df['obp']+merged_df['slg'])\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\214028105.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['OPS+'] = (((merged_df['ops'])/0.734)*100).round(0)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\214028105.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['HR'] = merged_df['hr650'].round(0)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\214028105.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['OBP'] = merged_df['obp'].round(3)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\214028105.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['bb650_pot'] = (merged_df['bb%_pot'] * 650)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\214028105.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['hr650_pot'] = (merged_df['hr%_pot'] * ((650 - merged_df['bb650_pot'])))\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\214028105.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['k650_pot'] = (merged_df['k%_pot'] * ((650 - merged_df['bb650_pot'])))\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\214028105.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['2b_pot'] = (merged_df['2b%_pot'] * ((650 - merged_df['bb650_pot']-merged_df['hr650_pot']-merged_df['k650_pot'])))\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\214028105.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['3b_pot'] = (merged_df['3b%_pot'] * ((650 - merged_df['bb650_pot']-merged_df['hr650_pot']-merged_df['k650_pot'])))\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\214028105.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['1b_pot'] = (merged_df['1b%_pot'] * ((650 - merged_df['bb650_pot']-merged_df['hr650_pot']-merged_df['k650_pot']-merged_df['2b_pot']-merged_df['3b_pot'])))\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\214028105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['obp_pot'] = ((merged_df['bb650_pot'] + merged_df['hr650_pot'] + merged_df['2b_pot'] + merged_df['3b_pot'] + merged_df['1b_pot']) / 650)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\214028105.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['slg_pot'] = (((merged_df['1b_pot'])+(2*merged_df['2b_pot'])+(3*merged_df['3b_pot'])+(4*merged_df['hr650_pot']))/(650-merged_df['bb650_pot']))\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\214028105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['ops_pot'] = (merged_df['obp_pot']+merged_df['slg_pot'])\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\214028105.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['OPS+_p'] = (((merged_df['ops_pot'])/0.734)*100).round(0)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\214028105.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['HR_p'] = ((merged_df['hr650_pot'])).round(0)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\214028105.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['OBP_p'] = merged_df['obp_pot'].round(3)\n"
     ]
    }
   ],
   "execution_count": 296
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:28.277364Z",
     "start_time": "2025-03-25T04:00:28.269106Z"
    }
   },
   "source": [
    "# calculate OPS+ for mlb career for each player_id\n",
    "\n",
    "merged_df['bb650_mlb'] = (merged_df['bb%_mlb'] * 650)\n",
    "merged_df['hr650_mlb'] = (merged_df['hr%_mlb'] * 650)\n",
    "merged_df['k650_mlb'] = (merged_df['k%_mlb'] * 650)\n",
    "merged_df['2b_mlb'] = (merged_df['2b%_mlb'] * 650)\n",
    "merged_df['3b_mlb'] = (merged_df['3b%_mlb'] * 650)\n",
    "merged_df['1b_mlb'] = (merged_df['1b%_mlb'] * 650)\n",
    "merged_df['obp_mlb'] = ((merged_df['bb650_mlb'] + merged_df['hr650_mlb'] + merged_df['2b_mlb'] + merged_df['3b_mlb'] + merged_df['1b_mlb']) / 650)\n",
    "merged_df['slg_mlb'] = (((merged_df['1b_mlb'])+(2*merged_df['2b_mlb'])+(3*merged_df['3b_mlb'])+(4*merged_df['hr650_mlb']))/(650-merged_df['bb650_mlb']))\n",
    "merged_df['ops_mlb'] = (merged_df['obp_mlb']+merged_df['slg_mlb'])\n",
    "merged_df['OPS+_mlb'] = (((merged_df['ops_mlb'])/0.734)*100).round(0)\n",
    "merged_df['HR_mlb'] = merged_df['hr650_mlb'].round(0)\n",
    "merged_df['OBP_mlb'] = merged_df['obp_mlb'].round(3)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1845836046.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['bb650_mlb'] = (merged_df['bb%_mlb'] * 650)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1845836046.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['hr650_mlb'] = (merged_df['hr%_mlb'] * 650)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1845836046.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['k650_mlb'] = (merged_df['k%_mlb'] * 650)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1845836046.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['2b_mlb'] = (merged_df['2b%_mlb'] * 650)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1845836046.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['3b_mlb'] = (merged_df['3b%_mlb'] * 650)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1845836046.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['1b_mlb'] = (merged_df['1b%_mlb'] * 650)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1845836046.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['obp_mlb'] = ((merged_df['bb650_mlb'] + merged_df['hr650_mlb'] + merged_df['2b_mlb'] + merged_df['3b_mlb'] + merged_df['1b_mlb']) / 650)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1845836046.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['slg_mlb'] = (((merged_df['1b_mlb'])+(2*merged_df['2b_mlb'])+(3*merged_df['3b_mlb'])+(4*merged_df['hr650_mlb']))/(650-merged_df['bb650_mlb']))\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1845836046.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['ops_mlb'] = (merged_df['obp_mlb']+merged_df['slg_mlb'])\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1845836046.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['OPS+_mlb'] = (((merged_df['ops_mlb'])/0.734)*100).round(0)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1845836046.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['HR_mlb'] = merged_df['hr650_mlb'].round(0)\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1845836046.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['OBP_mlb'] = merged_df['obp_mlb'].round(3)\n"
     ]
    }
   ],
   "execution_count": 297
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:28.294290Z",
     "start_time": "2025-03-25T04:00:28.291736Z"
    }
   },
   "source": [
    "# Determine if a player is a minor leaguer\n",
    "merged_df['minor'] = (merged_df['organization_id'] != merged_df['team_id']).astype(int)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\1680301505.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df['minor'] = (merged_df['organization_id'] != merged_df['team_id']).astype(int)\n"
     ]
    }
   ],
   "execution_count": 298
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:28.360934Z",
     "start_time": "2025-03-25T04:00:28.313751Z"
    }
   },
   "source": [
    "# look up which club each player plays for based on 'organization_id' and a lookup table\n",
    "club_lookup = pd.read_csv(pistachio_filepath + '/config/club_lookup.csv')\n",
    "\n",
    "# Merge the 'club' column to the dataframe\n",
    "merged_df = pd.merge(merged_df, club_lookup[['club_id', 'club']], left_on='organization_id', right_on='club_id', how='left')\n",
    "\n",
    "# Drop the 'club_id' column as it's no longer needed\n",
    "merged_df = merged_df.drop(columns='club_id')"
   ],
   "outputs": [],
   "execution_count": 299
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:28.380935Z",
     "start_time": "2025-03-25T04:00:28.374281Z"
    }
   },
   "source": [
    "# Read names from text file into a list - paste in here players to be flagged (eg players available in draft, or players in a shortlist or player search)\n",
    "# convert to lowercase so can read if ALL CAPS (i.e. in a shortlist)\n",
    "with open(pistachio_filepath + '/config/flagged.txt', 'r') as f:\n",
    "    drafted_names = [name.lower() for name in f.read().splitlines()]\n",
    "\n",
    "# Convert 'name' column to lowercase and check for membership\n",
    "merged_df['in_list'] = np.where(merged_df['name'].str.lower().isin(drafted_names), 'flagged', '')"
   ],
   "outputs": [],
   "execution_count": 300
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:28.540339Z",
     "start_time": "2025-03-25T04:00:28.393264Z"
    }
   },
   "source": [
    "# This compares a batter's OPS+ against a standard trajectory for a player of their age\n",
    "# Players are classified into three growth lanes (low, medium, high) based on their fielding position\n",
    "# Instead of using best_sWAR_pos, we now use our multi-position logic (field column)\n",
    "\n",
    "# Position groups:\n",
    "groupA = [\"1B\", \"DH\"]         # First Base or Designated Hitter (Lowest Priority)\n",
    "groupB = [\"C\", \"SS\", \"CF\"]    # Catcher, Shortstop, Center Field (Highest Priority)\n",
    "groupC = [\"2B\", \"3B\", \"LF\", \"RF\"]  # Second Base, Third Base, Left Field, Right Field (Medium Priority)\n",
    "\n",
    "# Track value dictionaries by age\n",
    "groupA_lookup = {\n",
    "    14: 64, 15: 65, 16: 65, 17: 66, 18: 68,\n",
    "    19: 72, 20: 76, 21: 83, 22: 91, 23: 99,\n",
    "    24: 103, 25: 107, 26: 108, 27: 110, 28: 110,\n",
    "    29: 110, 30: 110\n",
    "}\n",
    "groupB_lookup = {\n",
    "    14: 52, 15: 53, 16: 53, 17: 54, 18: 56,\n",
    "    19: 59, 20: 62, 21: 68, 22: 75, 23: 81,\n",
    "    24: 84, 25: 88, 26: 89, 27: 90, 28: 90,\n",
    "    29: 90, 30: 90\n",
    "}\n",
    "groupC_lookup = {\n",
    "    14: 58, 15: 59, 16: 59, 17: 60, 18: 62,\n",
    "    19: 65, 20: 69, 21: 75, 22: 83, 23: 90,\n",
    "    24: 93, 25: 98, 26: 99, 27: 100, 28: 100,\n",
    "    29: 100, 30: 100\n",
    "}\n",
    "\n",
    "# Extend each dictionary to handle ages 31 through 50 by repeating the final value\n",
    "for age in range(31, 51):\n",
    "    groupA_lookup[age] = 110\n",
    "    groupB_lookup[age] = 90\n",
    "    groupC_lookup[age] = 100\n",
    "\n",
    "def get_track_value(row):\n",
    "    \"\"\"\n",
    "    Returns a track value based on a player's age and fielding positions.\n",
    "    Uses multi-position eligibility (field column) instead of best_sWAR_pos.\n",
    "    Clamps age to [14..50].\n",
    "    Prioritization: Group B > Group C > Group A.\n",
    "    \"\"\"\n",
    "    # Ensure age is an integer\n",
    "    age = int(row['age'])\n",
    "    # Clamp age to the range [14..50] for lookup\n",
    "    if age < 14:\n",
    "        age = 14\n",
    "    elif age > 50:\n",
    "        age = 50\n",
    "\n",
    "    # Extract eligible positions from the 'field' column\n",
    "    positions = row['field'].split(\", \") if row['field'] else []\n",
    "\n",
    "    # Default track value if no valid position found\n",
    "    default_growth = 100  \n",
    "\n",
    "    # Determine the best track value based on position groups with the new prioritization\n",
    "    if any(pos in groupB for pos in positions):  # Highest priority\n",
    "        return groupB_lookup.get(age, 90)\n",
    "    elif any(pos in groupC for pos in positions):  # Second priority\n",
    "        return groupC_lookup.get(age, 100)\n",
    "    elif any(pos in groupA for pos in positions):  # Lowest priority\n",
    "        return groupA_lookup.get(age, 110)\n",
    "    else:\n",
    "        return default_growth  # If no valid position, assign default\n",
    "\n",
    "# Create the 'track' column using the updated position logic with new prioritization\n",
    "merged_df['track'] = merged_df.apply(get_track_value, axis=1)\n"
   ],
   "outputs": [],
   "execution_count": 301
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:28.960091Z",
     "start_time": "2025-03-25T04:00:28.553151Z"
    }
   },
   "source": [
    "# Calculate the OPS+ at age 21 and 27 for each player based on yearly growth factors for a median trajectory\n",
    "\n",
    "import math\n",
    "\n",
    "# Define the growth factors\n",
    "growth_factors = {\n",
    "    14: 0.00,\n",
    "    15: 0.01,\n",
    "    16: 0.00,\n",
    "    17: 0.02,\n",
    "    18: 0.04,\n",
    "    19: 0.05,\n",
    "    20: 0.06,\n",
    "    21: 0.09,\n",
    "    22: 0.10,\n",
    "    23: 0.08,\n",
    "    24: 0.04,\n",
    "    25: 0.05,\n",
    "    26: 0.01,\n",
    "    27: 0.01,\n",
    "    28: 0.00,\n",
    "}\n",
    "# Set ages 29 through 50 to zero\n",
    "for a in range(29, 51):\n",
    "    growth_factors[a] = 0.0\n",
    "\n",
    "def get_ops21(age, current_ops):\n",
    "    \"\"\" \n",
    "    Calculate projected OPS+ at age 21 based on yearly growth factors.\n",
    "    If age >= 22, returns 0.\n",
    "    If age == 21, returns current OPS+.\n",
    "    If age < 21, multiplies by growth rates for (age+1) to 21.\n",
    "    \"\"\"\n",
    "    if age >= 22:\n",
    "        return 0\n",
    "    elif age == 21:\n",
    "        return current_ops\n",
    "    \n",
    "    projected_ops = float(current_ops)\n",
    "    for next_age in range(age + 1, 22):\n",
    "        factor = growth_factors.get(next_age, 0.0)\n",
    "        projected_ops *= (1 + factor)\n",
    "    \n",
    "    return math.floor(projected_ops)\n",
    "\n",
    "def get_ops27(age, current_ops):\n",
    "    \"\"\" \n",
    "    Calculate projected OPS+ at age 27 based on yearly growth factors.\n",
    "    If age >= 27, returns current OPS+ (no growth applied).\n",
    "    If age < 27, multiplies by growth rates for (age+1) to 27.\n",
    "    \"\"\"\n",
    "    if age >= 27:\n",
    "        return current_ops\n",
    "    elif age == 27:\n",
    "        return current_ops\n",
    "    \n",
    "    projected_ops = float(current_ops)\n",
    "    for next_age in range(age + 1, 28):  # Project up to age 27\n",
    "        factor = growth_factors.get(next_age, 0.0)\n",
    "        projected_ops *= (1 + factor)\n",
    "    \n",
    "    return math.floor(projected_ops)\n",
    "\n",
    "# Apply functions to create the ops21 and ops27 columns in merged_df\n",
    "merged_df['ops21'] = merged_df.apply(\n",
    "    lambda row: get_ops21(row['age'], row['OPS+']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "merged_df['ops27'] = merged_df.apply(\n",
    "    lambda row: get_ops27(row['age'], row['OPS+']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "merged_df['Tpct'] = (merged_df['OPS+'] / merged_df['track'].replace(0, float('nan'))).round(2)\n",
    "\n",
    "# Add the onT column: If Tpct >= 1, set it to \"track\"\n",
    "merged_df['onT'] = merged_df.apply(lambda row: f\"{row['club']} track\" if row['Tpct'] >= 1 else \"\", axis=1)"
   ],
   "outputs": [],
   "execution_count": 302
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:29.135948Z",
     "start_time": "2025-03-25T04:00:28.974442Z"
    }
   },
   "source": [
    "# Function to determine the denominator used to calc PPct based on fielding position (i.e. to gauge how impressive potential OPS+ is)\n",
    "def get_divisor(row):\n",
    "    \"\"\"\n",
    "    Determines the divisor based on a player's fielding positions.\n",
    "    Uses multi-position eligibility (field column) instead of best_sWAR_pos.\n",
    "    Prioritization: Group B > Group C > Group A.\n",
    "    \"\"\"\n",
    "    positions = row['field'].split(\", \") if row['field'] else []\n",
    "\n",
    "    # Default divisor if no valid position is found\n",
    "    default_divisor = 100  \n",
    "\n",
    "    # Determine the divisor based on position groups\n",
    "    if any(pos in groupB for pos in positions):  # Highest priority (hardest positions)\n",
    "        return 90\n",
    "    elif any(pos in groupC for pos in positions):  # Medium priority\n",
    "        return 100\n",
    "    elif any(pos in groupA for pos in positions):  # Lowest priority (easiest positions)\n",
    "        return 110\n",
    "    else:\n",
    "        return default_divisor  # If no valid position, assign default\n",
    "\n",
    "# Add the Ppct column: OPS+_p divided by the appropriate divisor based on the new logic\n",
    "merged_df['Ppct'] = merged_df.apply(\n",
    "    lambda row: (row['OPS+_p'] / get_divisor(row)) if pd.notna(row['OPS+_p']) else None, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Round Ppct to 2 decimal places\n",
    "merged_df['Ppct'] = merged_df['Ppct'].round(2)\n",
    "\n",
    "# Add the Pscore column: Tpct * Ppct, rounded to 2 decimal places\n",
    "merged_df['Pscore'] = (merged_df['Tpct'] * merged_df['Ppct']).round(2)"
   ],
   "outputs": [],
   "execution_count": 303
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:29.158505Z",
     "start_time": "2025-03-25T04:00:29.149302Z"
    }
   },
   "source": [
    "# export a simple dataframe with the pitcher outputs in the 'reports' folder of this pistachio project\n",
    "columns = ['name', 'age', 'club', 'minor', 'ip', 'throws', 'sp_sWAR', 'rp_sWAR','sp_sWAR_pot', 'rp_sWAR_pot', 'FIP','FIP_pot', 'in_list']\n",
    "df = merged_df[columns]\n",
    "\n",
    "# change 'throws' so that 1 = R, 2 = L\n",
    "df['throws'] = df['throws'].replace({1: 'R', 2: 'L'})\n",
    "\n",
    "# Filter the DataFrame (WAR limit removes hitters and pitchers with no WAR potential)\n",
    "pitchers = df[(df['club'] == team_managed) | (df['sp_sWAR'] >= 0.1) | (df['rp_sWAR'] >= 0.1) | (df['sp_sWAR_pot'] >= 0.1) | (df['rp_sWAR_pot'] >= 0.1) | (df['in_list'] == 'flagged')]\n",
    "pitchers.rename(columns={\n",
    "    'sp_sWAR': 'sp',\n",
    "    'rp_sWAR': 'rp',\n",
    "    'sp_sWAR_pot': 'spP',\n",
    "    'rp_sWAR_pot': 'rpP'\n",
    "}, inplace=True)\n",
    "\n",
    "pitchers.to_csv(export_filepath + '/pitcher_sWAR.csv', index=False)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2627231672.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['throws'] = df['throws'].replace({1: 'R', 2: 'L'})\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\2627231672.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pitchers.rename(columns={\n"
     ]
    }
   ],
   "execution_count": 304
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:29.434989Z",
     "start_time": "2025-03-25T04:00:29.175448Z"
    }
   },
   "source": [
    "# Add new column 'OPS+_pF' based on 'has_pos'\n",
    "# this means the output is searchable for batting projections for players that 'have a position' in the field\n",
    "# and are not just 1b/dh prospects\n",
    "merged_df['OPS+_pF'] = merged_df.apply(lambda row: row['OPS+_p'] if row['has_pos'] == \"yes\" else -999, axis=1)\n",
    "# same for Pscore\n",
    "merged_df['PscoreF'] = merged_df.apply(lambda row: row['Pscore'] if row['has_pos'] == \"yes\" else -999, axis=1)"
   ],
   "outputs": [],
   "execution_count": 305
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:29.463210Z",
     "start_time": "2025-03-25T04:00:29.450881Z"
    }
   },
   "source": [
    "# round columns\n",
    "round_zero_dp = ['pa', 'HR', 'OPS+', 'HR_p', 'OPS+_p', 'OPS+_pF', 'HR_mlb']\n",
    "round_two_dp = [\n",
    "    'best_sWAR', 'c_sWAR', '1b_sWAR', '2b_sWAR', '3b_sWAR', 'ss_sWAR',\n",
    "    'lf_sWAR', 'cf_sWAR', 'rf_sWAR', 'dh_sWAR', 'best_sWAR_pot', 'c_sWAR_pot',\n",
    "    '1b_sWAR_pot', '2b_sWAR_pot', '3b_sWAR_pot', 'ss_sWAR_pot', 'lf_sWAR_pot',\n",
    "    'cf_sWAR_pot', 'rf_sWAR_pot', 'dh_sWAR_pot', 'toWAR', 'toWAR_pot',\n",
    "    'c_tdWAR', '1b_tdWAR', '2b_tdWAR', '3b_tdWAR', 'ss_tdWAR',\n",
    "    'lf_tdWAR', 'cf_tdWAR', 'rf_tdWAR', 'dh_tdWAR', 'sp_sWAR', 'rp_sWAR', \n",
    "    'sp_FIP', 'rp_FIP', 'sp_sWAR_pot', 'rp_sWAR_pot', 'sp_FIP_pot', 'rp_FIP_pot', 'FIP', 'FIP_pot', 'Pscore', 'PscoreF'\n",
    "]\n",
    "\n",
    "# Ensure empty strings are replaced before converting to int\n",
    "merged_df[round_zero_dp] = merged_df[round_zero_dp].replace('', 0).fillna(0).round(0).astype(int)\n",
    "\n",
    "# Fill NaN values in round_two_dp columns with -999 before rounding to 2 decimal places\n",
    "merged_df[round_two_dp] = merged_df[round_two_dp].fillna(-999).round(2)\n",
    "\n",
    "# Make HR_mlb blank if 0 or NaN\n",
    "merged_df['HR_mlb'] = merged_df['HR_mlb'].replace({0: '', np.nan: ''})"
   ],
   "outputs": [],
   "execution_count": 306
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:29.503184Z",
     "start_time": "2025-03-25T04:00:29.479112Z"
    }
   },
   "source": [
    "# Convert the DataFrame to HTML\n",
    "html = pitchers.to_html()\n",
    "\n",
    "# Add some JavaScript for sortable and filterable table\n",
    "html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html class=\"dark\">\n",
    "<head>\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Roboto&display=swap\" rel=\"stylesheet\">\n",
    "<script src=\"https://code.jquery.com/jquery-3.7.1.js\"></script>\n",
    "<script src=\"https://cdn.datatables.net/2.0.5/js/dataTables.js\"></script>\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.datatables.net/2.0.5/css/dataTables.dataTables.css\">\n",
    "<style>\n",
    "        :root.dark {\n",
    "            --dt-html-background: rgb(33, 37, 41);\n",
    "        }\n",
    "\n",
    "        html.dark {\n",
    "            background-color: var(--dt-html-background);\n",
    "            color: rgb(255, 255, 255);\n",
    "            font-family: 'Roboto', sans-serif;\n",
    "        }\n",
    "\n",
    "        html.dark table.dataTable > thead > tr > th,\n",
    "        html.dark table.dataTable > thead > tr > td {\n",
    "            border-bottom: 1px solid rgb(89, 91, 94);\n",
    "        }\n",
    "\n",
    "        html.dark table.dataTable > tfoot > tr > th,\n",
    "        html.dark table.dataTable > tfoot > tr > td {\n",
    "            border-top: 1px solid rgb(89, 91, 94);\n",
    "        }\n",
    "\n",
    "        html.dark .dt-container .dt-search input,\n",
    "        html.dark .dt-container .dt-length select {\n",
    "            border: 1px solid rgba(255, 255, 255, 0.2);\n",
    "            background-color: var(--dt-html-background);\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "%s\n",
    "<script>\n",
    "$(document).ready(function(){\n",
    "    $('table').DataTable({\n",
    "        \"paging\": true,\n",
    "        \"pageLength\": 50\n",
    "    });\n",
    "});\n",
    "</script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\" % html\n",
    "\n",
    "# Write the HTML string to a file\n",
    "with open(export_filepath + '/pitcher_sWAR.html', 'w') as f:\n",
    "    f.write(html)"
   ],
   "outputs": [],
   "execution_count": 307
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:29.521632Z",
     "start_time": "2025-03-25T04:00:29.518567Z"
    }
   },
   "source": [
    "# rename columns for use in batter output as required (some other columns are renamed below also)\n",
    "merged_df.rename(columns={\n",
    "    \"batting_ratings_overall_eye\": \"eye\",\n",
    "    \"batting_ratings_overall_power\": \"power\",\n",
    "    \"batting_ratings_overall_babip\": \"babip\",\n",
    "    \"batting_ratings_overall_gap\": \"gap\",\n",
    "    \"batting_ratings_overall_strikeouts\": \"avoidk\",\n",
    "    \"running_ratings_speed_y\": \"speed\",\n",
    "}, inplace=True)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 308
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:30.893675Z",
     "start_time": "2025-03-25T04:00:29.537533Z"
    }
   },
   "source": [
    "print(merged_df.head())\n",
    "\n",
    "# export merged_df to csv\n",
    "merged_df.to_csv(export_filepath + '/merged_df1329.csv', index=False)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   player_id  team_id  league_id  position  role first_name    last_name  age  \\\n",
      "0          2        0          0         3     0       John     Nogowski   32   \n",
      "1          3        0          0         4     0    Patrick      Dorrian   28   \n",
      "2          6       18        203         1    11     Carlos        Rodón   32   \n",
      "3          7      270        210         4     0     George  Lombard Jr.   19   \n",
      "4          8        0          0         1    11    Brandon     Finnegan   31   \n",
      "\n",
      "  date_of_birth  weight  ...  in_list  track  ops21  ops27  Tpct        onT  \\\n",
      "0      1993-1-5     229  ...             100    0.0   99.0  0.99              \n",
      "1     1996-6-26     187  ...             100    0.0   88.0  0.88              \n",
      "2    1992-12-10     236  ...             100    0.0   47.0  0.47              \n",
      "3      2005-6-2     192  ...              65   86.0  114.0  1.15  NYY track   \n",
      "4     1993-4-14     213  ...             100    0.0   44.0  0.44              \n",
      "\n",
      "   Ppct  Pscore  OPS+_pF  PscoreF  \n",
      "0  0.99    0.98     -999  -999.00  \n",
      "1  0.89    0.78     -999  -999.00  \n",
      "2  0.47    0.22     -999  -999.00  \n",
      "3  1.03    1.18      103     1.18  \n",
      "4  0.44    0.19     -999  -999.00  \n",
      "\n",
      "[5 rows x 365 columns]\n"
     ]
    }
   ],
   "execution_count": 309
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:30.964446Z",
     "start_time": "2025-03-25T04:00:30.912212Z"
    }
   },
   "source": [
    "# export a simple dataframe with the batter WAR outputs in the 'reports' folder of this pistachio project\n",
    "columns = ['name', 'age', 'club', 'minor', 'pa', 'best_sWAR', 'best_sWAR_pos', 'field', 'bats', 'HR_mlb', 'HR', 'OBP', 'OPS+', 'best_sWAR_pot', 'HR_p', 'OBP_p', 'OPS+_p', 'OPS+_pF', 'Tpct', 'c_sWAR', '1b_sWAR', '2b_sWAR', '3b_sWAR', 'ss_sWAR', 'lf_sWAR', 'cf_sWAR', 'rf_sWAR', 'dh_sWAR', 'c_sWAR_pot', '1b_sWAR_pot', '2b_sWAR_pot', '3b_sWAR_pot', 'ss_sWAR_pot', 'lf_sWAR_pot', 'cf_sWAR_pot', 'rf_sWAR_pot', 'dh_sWAR_pot', 'toWAR', 'toWAR_pot', 'c_tdWAR', '1b_tdWAR', '2b_tdWAR', '3b_tdWAR', 'ss_tdWAR', 'lf_tdWAR', 'cf_tdWAR', 'rf_tdWAR', 'dh_tdWAR', 'in_list']\n",
    "df = merged_df[columns]\n",
    "\n",
    "# change 'bats' so that 1 = R, 2 = L, 3 = S\n",
    "df['bats'] = df['bats'].replace({1: 'R', 2: 'L', 3: 'S'})\n",
    "\n",
    "# Filter the DataFrame - include all of the club I manage and any player with a best_sWAR or best_sWAR_pot greater than or equal to 0.1\n",
    "df = df[(df['club'] == team_managed) | (df['best_sWAR'] >= 0.1) | (df['best_sWAR_pot'] >= 0.1) | (df ['in_list'] == 'flagged')]\n",
    "\n",
    "df = df.dropna(subset=['OPS+'])\n",
    "df = df.dropna(subset=['OPS+_p'])\n",
    "df = df.rename(columns={\n",
    "    'best_sWAR': 'best',\n",
    "    'best_sWAR_pos': 'pos',\n",
    "    'c_sWAR': 'c',\n",
    "    '1b_sWAR': '1b',\n",
    "    '2b_sWAR': '2b',\n",
    "    '3b_sWAR': '3b',\n",
    "    'ss_sWAR': 'ss',\n",
    "    'lf_sWAR': 'lf',\n",
    "    'cf_sWAR': 'cf',\n",
    "    'rf_sWAR': 'rf',\n",
    "    'dh_sWAR': 'dh',\n",
    "    'best_sWAR_pot': 'bestP',\n",
    "    'c_sWAR_pot': 'cP',\n",
    "    '1b_sWAR_pot': '1bP',\n",
    "    '2b_sWAR_pot': '2bP',\n",
    "    '3b_sWAR_pot': '3bP',\n",
    "    'ss_sWAR_pot': 'ssP',\n",
    "    'lf_sWAR_pot': 'lfP',\n",
    "    'cf_sWAR_pot': 'cfP',\n",
    "    'rf_sWAR_pot': 'rfP',\n",
    "    'dh_sWAR_pot': 'dhP',\n",
    "    'toWAR_pot': 'toWARP'\n",
    "})\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv(export_filepath + '/batter_sWAR.csv', index=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_27112\\4055480410.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['bats'] = df['bats'].replace({1: 'R', 2: 'L', 3: 'S'})\n"
     ]
    }
   ],
   "execution_count": 310
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T04:00:32.081160Z",
     "start_time": "2025-03-25T04:00:30.984429Z"
    }
   },
   "source": [
    "# Convert the DataFrame to HTML\n",
    "html = df.to_html(index=False)\n",
    "\n",
    "# Add some JavaScript for sortable and filterable table\n",
    "html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html class=\"dark\">\n",
    "<head>\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Roboto&display=swap\" rel=\"stylesheet\">\n",
    "<script src=\"https://code.jquery.com/jquery-3.7.1.js\"></script>\n",
    "<script src=\"https://cdn.datatables.net/2.0.5/js/dataTables.js\"></script>\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.datatables.net/2.0.5/css/dataTables.dataTables.css\">\n",
    "<style>\n",
    "        :root.dark {\n",
    "            --dt-html-background: rgb(33, 37, 41);\n",
    "        }\n",
    "\n",
    "        html.dark {\n",
    "            background-color: var(--dt-html-background);\n",
    "            color: rgb(255, 255, 255);\n",
    "            font-family: 'Roboto', sans-serif;\n",
    "        }\n",
    "\n",
    "        html.dark table.dataTable > thead > tr > th,\n",
    "        html.dark table.dataTable > thead > tr > td {\n",
    "            border-bottom: 1px solid rgb(89, 91, 94);\n",
    "        }\n",
    "\n",
    "        html.dark table.dataTable > tfoot > tr > th,\n",
    "        html.dark table.dataTable > tfoot > tr > td {\n",
    "            border-top: 1px solid rgb(89, 91, 94);\n",
    "        }\n",
    "\n",
    "        html.dark .dt-container .dt-search input,\n",
    "        html.dark .dt-container .dt-length select {\n",
    "            border: 1px solid rgba(255, 255, 255, 0.2);\n",
    "            background-color: var(--dt-html-background);\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "%s\n",
    "<script>\n",
    "$(document).ready(function(){\n",
    "    $('table').DataTable({\n",
    "        \"paging\": true,\n",
    "        \"pageLength\": 50\n",
    "    });\n",
    "});\n",
    "</script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\" % html\n",
    "\n",
    "# Write the HTML string to a file\n",
    "with open(export_filepath + '/batter_sWAR.html', 'w') as f:\n",
    "    f.write(html)\n",
    "    \n",
    "    "
   ],
   "outputs": [],
   "execution_count": 311
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pistachio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
